{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud PoC — DuckDB + Embeddings + Ollama\n",
    "\n",
    "This notebook demonstrates an end-to-end PoC:\n",
    "- create canonical tables in DuckDB\n",
    "- ingest synthetic transactions\n",
    "- compute embeddings (sentence-transformers)\n",
    "- build a local ANN index (faiss / hnswlib / sklearn fallback)\n",
    "- perform retrieval, assemble prompt and call Ollama (local LLM)\n",
    "- persist LLM result and provenance back into DuckDB\n",
    "\n",
    "Notes:\n",
    "- Ensure your environment has the dependencies from `requirements.txt` installed.\n",
    "- Ensure Ollama is running and reachable at OLLAMA_URL (default http://localhost:11434/api/generate).\n",
    "- The notebook auto-falls back to hnswlib or sklearn NearestNeighbors if faiss is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "960c91c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud_poc.duckdb\n"
     ]
    }
   ],
   "source": [
    "# Configuration & imports\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import hashlib\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Embedding lib\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ANN fallbacks\n",
    "HAS_FAISS = False\n",
    "try:\n",
    "    import faiss\n",
    "    HAS_FAISS = True\n",
    "except Exception:\n",
    "    HAS_FAISS = False\n",
    "\n",
    "HAS_HNSW = False\n",
    "try:\n",
    "    import hnswlib\n",
    "    HAS_HNSW = True\n",
    "except Exception:\n",
    "    HAS_HNSW = False\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Ollama endpoint (adjust if different in your setup)\n",
    "OLLAMA_URL = os.environ.get('OLLAMA_URL', 'http://localhost:11434/api/generate')\n",
    "OLLAMA_MODEL = os.environ.get('OLLAMA_MODEL', 'olmo-3')  # replace with your pulled model name\n",
    "\n",
    "# DuckDB path\n",
    "DB_PATH = os.environ.get('DB_PATH', 'fraud_poc.duckdb')\n",
    "print(DB_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b006d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities: prompt hashing and calling Ollama\n",
    "def prompt_hash(prompt_text: str) -> str:\n",
    "    return hashlib.sha256(prompt_text.encode('utf-8')).hexdigest()\n",
    "\n",
    "def call_ollama(model: str, prompt_text: str, temperature: float = 0.0, timeout: int = 60) -> Dict[str, Any]:\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'prompt': prompt_text,\n",
    "        'temperature': temperature\n",
    "    }\n",
    "    start = time.time()\n",
    "    resp = requests.post(OLLAMA_URL, json=payload, timeout=timeout)\n",
    "    resp.raise_for_status()\n",
    "    elapsed_ms = int((time.time() - start) * 1000)\n",
    "    try:\n",
    "        data = resp.json()\n",
    "    except ValueError:\n",
    "        data = {'text': resp.text}\n",
    "    # Normalize text extraction (common keys)\n",
    "    text = data.get('text') or data.get('response') or data.get('content') or resp.text\n",
    "    return {\n",
    "        'llm_provider': 'ollama_local',\n",
    "        'llm_model': model,\n",
    "        'llm_response_raw': text,\n",
    "        'llm_response_json': data if isinstance(data, dict) else None,\n",
    "        'latency_ms': elapsed_ms,\n",
    "        'prompt_hash': prompt_hash(prompt_text),\n",
    "        'call_id': str(uuid.uuid4())\n",
    "    }\n",
    "\n",
    "def try_parse_json(s: str):\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "306f7cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created tables (if not existing) in fraud_poc.duckdb\n"
     ]
    }
   ],
   "source": [
    "# Create DuckDB connection and required tables (idempotent)\n",
    "con = duckdb.connect(DB_PATH)\n",
    "\n",
    "CREATE_TRANSACTIONS = '''\n",
    "CREATE TABLE IF NOT EXISTS transactions (\n",
    "  tx_id VARCHAR PRIMARY KEY,\n",
    "  account_id VARCHAR,\n",
    "  amount DOUBLE,\n",
    "  currency VARCHAR,\n",
    "  merchant VARCHAR,\n",
    "  description VARCHAR,\n",
    "  timestamp TIMESTAMP,\n",
    "  ingestion_job_id VARCHAR,\n",
    "  raw_source VARCHAR,\n",
    "  pii_masked BOOLEAN DEFAULT FALSE,\n",
    "  created_at TIMESTAMP DEFAULT current_timestamp\n",
    ");\n",
    "'''\n",
    "\n",
    "CREATE_EMBEDDINGS = '''\n",
    "CREATE TABLE IF NOT EXISTS embeddings (\n",
    "  tx_id VARCHAR PRIMARY KEY,\n",
    "  emb_json TEXT,\n",
    "  emb_model VARCHAR,\n",
    "  emb_created_at TIMESTAMP DEFAULT current_timestamp,\n",
    "  emb_job_id VARCHAR\n",
    ");\n",
    "'''\n",
    "\n",
    "CREATE_LLM = '''\n",
    "CREATE TABLE IF NOT EXISTS llm_results (\n",
    "  id VARCHAR PRIMARY KEY,\n",
    "  tx_id VARCHAR,\n",
    "  llm_model VARCHAR,\n",
    "  llm_provider VARCHAR,\n",
    "  llm_prompt_hash VARCHAR,\n",
    "  llm_prompt VARCHAR,\n",
    "  llm_response VARCHAR,\n",
    "  parsed_response JSON,\n",
    "  risk_score DOUBLE,\n",
    "  evidence_tx_ids JSON,\n",
    "  call_latency_ms INTEGER,\n",
    "  provenance JSON,\n",
    "  created_at TIMESTAMP DEFAULT current_timestamp\n",
    ");\n",
    "'''\n",
    "\n",
    "con.execute(CREATE_TRANSACTIONS)\n",
    "con.execute(CREATE_EMBEDDINGS)\n",
    "con.execute(CREATE_LLM)\n",
    "print('Created tables (if not existing) in', DB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a16e186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 200 transactions\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic transactions and insert into DuckDB\n",
    "import datetime\n",
    "\n",
    "n = 200\n",
    "rng = np.random.default_rng(42)\n",
    "txs = []\n",
    "for i in range(n):\n",
    "    tx_id = f\"tx_{i+1:06d}\"\n",
    "    account = f\"acct_{rng.integers(1,50):04d}\"\n",
    "    amount = float(np.round(rng.normal(50, 120), 2))\n",
    "    merchant = rng.choice(['store_a','store_b','online_shop','gas_station','restaurant'])\n",
    "    desc = f\"purchase at {merchant} for ${amount:.2f}\"\n",
    "    ts = datetime.datetime.utcnow() - datetime.timedelta(minutes=int(rng.integers(0, 60*24)))\n",
    "    txs.append((tx_id, account, amount, 'USD', merchant, desc, ts, 'ingest_0', 'synthetic', False))\n",
    "\n",
    "df = pd.DataFrame(txs, columns=['tx_id','account_id','amount','currency','merchant','description','timestamp','ingestion_job_id','raw_source','pii_masked'])\n",
    "\n",
    "con.register('df_tx', df)\n",
    "con.execute(\"INSERT OR REPLACE INTO transactions (tx_id, account_id, amount, currency, merchant, description, timestamp, ingestion_job_id, raw_source, pii_masked) SELECT * FROM df_tx\")\n",
    "print('Inserted', len(df), 'transactions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dff26945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 7/7 [00:00<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 200 embeddings in DuckDB\n"
     ]
    }
   ],
   "source": [
    "# Compute embeddings with sentence-transformers and store in embeddings table\n",
    "embed_model_name = 'all-MiniLM-L6-v2'\n",
    "print('Loading embedding model:', embed_model_name)\n",
    "embedder = SentenceTransformer(embed_model_name)\n",
    "\n",
    "# Load transactions into a DataFrame (from DuckDB)\n",
    "df_tx = con.execute('SELECT tx_id, description FROM transactions').df()\n",
    "texts = df_tx['description'].tolist()\n",
    "vectors = embedder.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "\n",
    "import json\n",
    "rows = []\n",
    "for tx_id, vec in zip(df_tx['tx_id'].tolist(), vectors):\n",
    "    rows.append((tx_id, json.dumps(vec.tolist()), embed_model_name, None))\n",
    "\n",
    "df_emb = pd.DataFrame(rows, columns=['tx_id','emb_json','emb_model','emb_job_id'])\n",
    "con.register('df_emb', df_emb)\n",
    "con.execute(\"INSERT OR REPLACE INTO embeddings (tx_id, emb_json, emb_model, emb_job_id) SELECT * FROM df_emb\")\n",
    "print('Stored', len(df_emb), 'embeddings in DuckDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dc87ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built FAISS IndexFlatIP with 200 vectors\n"
     ]
    }
   ],
   "source": [
    "# Build an in-memory ANN index (faiss preferred, then hnswlib, then sklearn)\n",
    "emb_matrix = np.vstack([np.array(json.loads(x)).astype('float32') for x in con.execute('SELECT emb_json FROM embeddings ORDER BY emb_created_at').df()['emb_json']])\n",
    "ids = con.execute('SELECT tx_id FROM embeddings ORDER BY emb_created_at').df()['tx_id'].tolist()\n",
    "id_to_index = {tx_id: idx for idx, tx_id in enumerate(ids)}\n",
    "\n",
    "ann_index = None\n",
    "ann_backend = None\n",
    "dim = emb_matrix.shape[1]\n",
    "\n",
    "if HAS_FAISS:\n",
    "    import faiss\n",
    "    # normalize for cosine similarity\n",
    "    xb = emb_matrix.copy()\n",
    "    faiss.normalize_L2(xb)\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(xb)\n",
    "    ann_index = index\n",
    "    ann_backend = 'faiss'\n",
    "    print('Built FAISS IndexFlatIP with', xb.shape[0], 'vectors')\n",
    "elif HAS_HNSW:\n",
    "    import hnswlib\n",
    "    p = hnswlib.Index(space='cosine', dim=dim)\n",
    "    p.init_index(max_elements=emb_matrix.shape[0], ef_construction=200, M=16)\n",
    "    p.add_items(emb_matrix, np.arange(emb_matrix.shape[0]))\n",
    "    p.set_ef(50)\n",
    "    ann_index = p\n",
    "    ann_backend = 'hnswlib'\n",
    "    print('Built hnswlib index with', emb_matrix.shape[0], 'vectors')\n",
    "else:\n",
    "    # sklearn brute-force as fallback\n",
    "    nbrs = NearestNeighbors(n_neighbors=10, metric='cosine', algorithm='brute').fit(emb_matrix)\n",
    "    ann_index = nbrs\n",
    "    ann_backend = 'sklearn'\n",
    "    print('Built sklearn NearestNeighbors fallback (brute)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a0939f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval helper\n",
    "def retrieve_topk(query_vec: np.ndarray, k: int = 5) -> List[Tuple[str, float]]:\n",
    "    q = query_vec.astype('float32')\n",
    "    if ann_backend == 'faiss':\n",
    "        qn = q.copy()\n",
    "        faiss.normalize_L2(qn)\n",
    "        D, I = ann_index.search(qn.reshape(1, -1), k)\n",
    "        # FAISS IndexFlatIP returns inner product; since we normalized, it's cosine similarity\n",
    "        return [(ids[int(i)], float(D[0][idx])) for idx, i in enumerate(I[0])] \n",
    "    elif ann_backend == 'hnswlib':\n",
    "        labels, distances = ann_index.knn_query(q, k=k)\n",
    "        return [(ids[int(lbl)], float(dist)) for lbl, dist in zip(labels[0], distances[0])]\n",
    "    else:\n",
    "        D, I = ann_index.kneighbors(q.reshape(1, -1), n_neighbors=k, return_distance=True)\n",
    "        return [(ids[int(i)], float(D[0][idx])) for idx, i in enumerate(I[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21caad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_topk_safe(q_vec, k=5, con=None, embeddings_table=\"embeddings\"):\n",
    "    \"\"\"\n",
    "    Defensive top-k retrieval.\n",
    "    - q_vec: 1D array-like vector\n",
    "    - k: number results\n",
    "    - con: duckdb connection or None; if None we open a temporary connection (adjust as needed)\n",
    "    - embeddings_table: table name; assumed columns (tx_id, emb_json) where emb_json is JSON array\n",
    "    Returns list of tuples (tx_id, score, metadata_if_any)\n",
    "    \"\"\"\n",
    "    # normalize q_vec to 1D numpy array\n",
    "    q = np.asarray(q_vec)\n",
    "    if q.ndim > 1 and q.shape[0] == 1:\n",
    "        q = q.reshape(-1)\n",
    "    if q.ndim != 1:\n",
    "        raise ValueError(f\"Expected 1D q_vec, got shape {q.shape}\")\n",
    "\n",
    "    # get rows from DB - FIX: use tx_id instead of id, and emb_json instead of embedding\n",
    "    if con is None:\n",
    "        con = duckdb.connect()  # adjust to your DB path or pass your existing connection\n",
    "    \n",
    "    try:\n",
    "        # Match your actual schema: tx_id, emb_json, emb_model\n",
    "        rows = con.execute(f\"SELECT tx_id, emb_json FROM {embeddings_table}\").fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching embeddings: {e}\")\n",
    "        return []\n",
    "\n",
    "    # defensive processing\n",
    "    scored = []\n",
    "    for i, row in enumerate(rows):\n",
    "        if row is None or not isinstance(row, (tuple, list)):\n",
    "            continue\n",
    "        # ensure we have at least tx_id and emb_json\n",
    "        if len(row) < 2:\n",
    "            continue\n",
    "        \n",
    "        tx_id = row[0]\n",
    "        emb_json = row[1]\n",
    "        \n",
    "        # Parse JSON string to numpy array\n",
    "        try:\n",
    "            vec = np.asarray(json.loads(emb_json), dtype=float)\n",
    "        except Exception:\n",
    "            # couldn't parse embedding JSON; skip\n",
    "            continue\n",
    "        \n",
    "        # guard shapes\n",
    "        if vec.shape != q.shape:\n",
    "            # attempt reshape if needed\n",
    "            try:\n",
    "                vec = vec.reshape(q.shape)\n",
    "            except Exception:\n",
    "                # incompatible shape\n",
    "                continue\n",
    "        \n",
    "        # compute cosine similarity (normalized dot product)\n",
    "        q_norm = np.linalg.norm(q)\n",
    "        vec_norm = np.linalg.norm(vec)\n",
    "        if q_norm > 0 and vec_norm > 0:\n",
    "            score = float(np.dot(q, vec) / (q_norm * vec_norm))\n",
    "        else:\n",
    "            score = 0.0\n",
    "        \n",
    "        scored.append((tx_id, score))\n",
    "\n",
    "    # sort and return top-k\n",
    "    scored.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scored[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41be0f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.33178493e-02  4.36213091e-02 -2.96768006e-02 -2.38433573e-02\n",
      "  3.16798910e-02 -3.29891555e-02  1.99093986e-02  8.80701244e-02\n",
      " -4.87000719e-02  1.89901181e-02  6.81477338e-02  7.00053051e-02\n",
      " -1.75664909e-02 -7.66963586e-02  2.75932886e-02 -1.58610474e-02\n",
      "  3.55156884e-02 -5.25271781e-02 -2.33377498e-02 -4.94899265e-02\n",
      " -5.46921380e-02 -2.23579593e-02  1.63522474e-02  5.45342714e-02\n",
      " -2.60659140e-02 -2.36302763e-02 -2.80885473e-02  3.04723773e-02\n",
      "  2.05742032e-03 -1.01760760e-01 -9.36753955e-03  6.86744675e-02\n",
      "  8.00207555e-02  2.78094765e-02 -1.06129283e-02 -2.18146462e-02\n",
      " -5.74116819e-02 -8.46812576e-02 -6.19765092e-03 -3.69384214e-02\n",
      "  5.57370707e-02  1.63095817e-02 -5.85012473e-02  3.43981273e-02\n",
      "  2.47597285e-02  3.76512967e-02  1.03835156e-02  1.06246561e-01\n",
      "  5.54109477e-02  6.80532679e-02 -6.85372800e-02  3.78160812e-02\n",
      " -4.22982052e-02  1.42525497e-03 -1.03825130e-01 -4.58065644e-02\n",
      "  2.23871768e-02 -5.65555431e-02 -7.50781095e-04 -2.49073189e-02\n",
      "  4.00769413e-02 -3.24188061e-02  7.10542649e-02 -2.47893599e-03\n",
      " -5.52631319e-02  4.59474213e-02 -3.15150432e-02 -8.05406459e-03\n",
      " -5.08239977e-02  4.23666872e-02  9.81662273e-02 -2.83173546e-02\n",
      " -5.05717546e-02  8.63679945e-02  2.37440951e-02 -4.30855602e-02\n",
      "  3.34774666e-02 -1.47955418e-02 -4.08431403e-02  5.84516488e-02\n",
      " -3.07534654e-02  3.63791436e-02 -3.19880061e-02 -9.57530439e-02\n",
      " -2.71357149e-02  1.23933479e-02  5.68420514e-02 -2.86736689e-03\n",
      "  8.07498470e-02 -6.50416762e-02  6.09210655e-02 -7.33552035e-04\n",
      " -5.62450057e-03 -6.09819265e-03 -2.84133293e-02 -6.42745718e-02\n",
      "  2.86567155e-02 -3.36517096e-02  5.39507046e-02  3.03997262e-03\n",
      "  8.61735120e-02  7.66928867e-02  6.50029108e-02 -4.62733097e-02\n",
      " -4.58869934e-02 -2.80379578e-02  1.56277530e-02  9.83828306e-02\n",
      "  9.63478960e-05 -3.62877734e-02 -9.11301896e-02 -2.93454863e-02\n",
      "  2.91334912e-02  1.71876643e-02  3.60177122e-02  1.10517651e-01\n",
      " -7.51788169e-02  2.57890206e-02  3.69566903e-02 -4.93163541e-02\n",
      "  1.00514591e-01  4.41329964e-02 -1.85236279e-02 -8.99669230e-02\n",
      " -6.56409413e-02  1.23336557e-02 -6.97493274e-03 -1.80555510e-33\n",
      " -5.65982871e-02  4.62253280e-02 -6.45497516e-02 -5.37416227e-02\n",
      " -3.02761216e-02  3.97381224e-02  1.07959233e-01  6.03055581e-02\n",
      " -1.05989359e-01  5.00855520e-02 -1.29625546e-02 -6.41943561e-03\n",
      "  4.19694837e-03  1.28067687e-01  3.73525219e-03  2.23758444e-03\n",
      "  2.32583862e-02  2.22909488e-02  8.29998106e-02 -3.93439569e-02\n",
      "  5.12855537e-02 -4.71206754e-02  2.15604529e-03  8.22331905e-02\n",
      " -2.19341996e-03 -1.19517958e-02  2.21722648e-02  1.14290230e-01\n",
      "  9.68511552e-02 -1.01252673e-02  1.15398243e-02 -9.23375189e-02\n",
      "  1.86906606e-02  3.59326228e-02  3.70331807e-03  4.91718389e-03\n",
      " -3.78202423e-02 -2.72263326e-02  6.67314231e-02 -3.15762684e-02\n",
      " -4.05340195e-02  6.59682602e-02 -5.84440455e-02  2.69556120e-02\n",
      " -8.55465084e-02  6.05993345e-02 -5.57589196e-02  1.25055108e-02\n",
      " -3.14539149e-02  4.05834941e-03 -5.48876598e-02 -5.72625175e-03\n",
      "  3.78068746e-03  9.85751897e-02 -5.52897342e-02 -5.79306073e-02\n",
      "  4.99658007e-03 -4.51861024e-02 -1.00714555e-02 -5.23793846e-02\n",
      "  6.52087107e-02 -7.16215074e-02  1.63471140e-02  3.76561917e-02\n",
      " -5.79952374e-02 -3.57650556e-02  6.83331955e-03 -5.72807565e-02\n",
      " -3.29363439e-03 -3.97743192e-03  2.38987058e-02  7.80623779e-02\n",
      "  1.04513377e-01 -7.25324601e-02 -7.59446016e-03 -1.07035704e-01\n",
      " -2.41991244e-02  1.23459123e-01  1.27889942e-02  2.68352050e-02\n",
      " -5.39714377e-03 -3.38471122e-02  8.54090378e-02  3.11672110e-02\n",
      " -5.37746102e-02  2.89142579e-02  2.48954669e-02  2.21288744e-02\n",
      " -3.11103947e-02  6.52825320e-03 -3.77967618e-02  6.33706525e-02\n",
      " -3.83093357e-02 -3.60653773e-02  4.88146394e-02  8.20570729e-34\n",
      " -3.89968976e-02 -4.11213264e-02  1.24061052e-02  7.07016513e-02\n",
      " -6.21127598e-02  1.64687000e-02 -6.92424029e-02  7.66131654e-02\n",
      " -1.78234987e-02  1.01413205e-02 -2.28352845e-02  5.88937551e-02\n",
      "  3.70870642e-02 -4.41571400e-02  8.86144862e-02 -3.86848785e-02\n",
      "  6.90427348e-02 -7.54696131e-03  9.02675241e-02 -1.69293601e-02\n",
      "  4.31800820e-02 -4.72031757e-02  1.82785299e-02 -8.48258473e-03\n",
      " -3.43226828e-02  3.15933004e-02 -2.35056523e-02 -3.97064984e-02\n",
      " -5.89159355e-02 -3.67077515e-02 -3.80296190e-03 -2.78962683e-02\n",
      " -6.38919771e-02  5.68204112e-02 -5.24459919e-03 -3.02256811e-02\n",
      " -3.93540040e-02  6.14927821e-02  5.46450205e-02  2.93106493e-02\n",
      "  4.39270250e-02  8.91106762e-03 -1.24160293e-02 -5.89508452e-02\n",
      " -2.03573518e-02 -8.24943483e-02 -4.84556676e-06 -3.26754004e-02\n",
      "  7.26383850e-02  3.64080742e-02 -4.71562967e-02  1.06400631e-01\n",
      "  2.77001299e-02 -5.70068136e-02 -4.06355411e-02  9.58451480e-02\n",
      "  1.39586926e-02  3.20531428e-03 -2.36132462e-02 -1.27380705e-02\n",
      " -4.55239788e-04  5.03079034e-02 -3.32759470e-02 -3.02265156e-02\n",
      "  4.30013351e-02 -4.78896033e-03  7.03477859e-02 -4.16063443e-02\n",
      "  9.53212827e-02  3.52376066e-02 -3.03099137e-02  2.57820096e-02\n",
      " -1.65845659e-02  5.82627486e-03 -6.86877593e-02 -4.34595868e-02\n",
      " -1.89839844e-02  6.97867647e-02  3.20714642e-03 -3.37043707e-03\n",
      "  3.67758498e-02  6.05916884e-03  1.49579853e-01  2.59557031e-02\n",
      "  5.70718059e-03 -5.80774508e-02 -6.01018891e-02  1.89252719e-02\n",
      " -7.91843515e-03  1.19769676e-02 -3.03787440e-02 -3.42471302e-02\n",
      " -2.94332877e-02 -4.21515740e-02  1.59250647e-02 -1.31375879e-08\n",
      "  5.94679341e-02  7.60191865e-03  6.17691018e-02  8.78606215e-02\n",
      "  9.68067050e-02 -1.80099625e-02  1.70298163e-02  1.15774475e-01\n",
      " -9.00519118e-02  5.47425821e-02 -3.53222415e-02 -7.23305419e-02\n",
      " -7.02888891e-02  8.90492275e-03 -1.86178870e-02 -1.08766340e-01\n",
      " -6.21744953e-02 -1.46334982e-02 -4.34379578e-02 -5.61520718e-02\n",
      " -6.15435326e-03  3.69497873e-02  5.66249005e-02 -6.65185973e-03\n",
      "  1.68399829e-02  4.55338769e-02  4.86877300e-02  1.00130767e-01\n",
      " -4.60528769e-02 -3.87345292e-02  1.53907165e-02  1.82158649e-02\n",
      " -2.27783192e-02 -3.76624763e-02  5.28048575e-02 -1.26851305e-01\n",
      " -2.88047474e-02  2.73000170e-02 -3.31353620e-02 -8.03118348e-02\n",
      " -5.96478917e-02 -5.38920648e-02  1.84042677e-02 -1.64076146e-02\n",
      "  4.30215485e-02 -2.60787047e-02 -1.00609981e-01 -9.92480814e-02\n",
      "  5.71765192e-02  3.00775729e-02 -1.26770148e-02 -4.94331494e-03\n",
      "  4.05964591e-02  7.01035708e-02 -2.39560250e-02 -5.88130243e-02\n",
      " -2.95434017e-02  3.75645421e-03  3.73128476e-03  3.97504792e-02\n",
      " -6.90142810e-03 -1.20459467e-01 -5.35585508e-02  3.53783853e-02]\n",
      "topk: [('tx_000022', 0.7461081066146185), ('tx_000025', 0.7443864894470535), ('tx_000185', 0.7416322502745024), ('tx_000074', 0.7362775983911812), ('tx_000106', 0.7312641315248966)]\n",
      "\n",
      "Prompt preview:\n",
      " You are a fraud analyst assistant. Given the incoming transaction and similar historical transactions, output JSON with fields: {\"risk_score\": \"float 0..1\", \"explanation\": \"string\", \"evidence_tx_ids\": \"list\"}.\n",
      "\n",
      "Incoming transaction:\n",
      "tx_live_0001 | online_shop | $399.99 | large purchase at online_shop\n",
      "\n",
      "Retrieved similar historical transactions:\n",
      "- tx_000022 | online_shop | $11.64 | purchase at online_shop for $11.64\n",
      "- tx_000025 | online_shop | $9.81 | purchase at online_shop for $9.81\n",
      "- tx_000185 | online_shop | $91.85 | purchase at online_shop for $91.85\n",
      "- tx_000074 | online_shop | $0.69 | purchase at online_shop for $0.69\n",
      "- tx_000106 | online_shop | $33.94 | purchase at online_shop for $33.94\n",
      "\n",
      "Return only valid JSON.\n",
      "Timeout on attempt 1/3. Retrying in 5s...\n",
      "Ollama call latency (ms): 759771\n",
      "Inserted llm_results id= 65f50de2-c08e-409a-bdff-a7e0f1b50c63\n"
     ]
    }
   ],
   "source": [
    "# Simulate an incoming transaction, retrieve similar historical cases, call Ollama, and persist result\n",
    "incoming = {\n",
    "    'tx_id': 'tx_live_0001',\n",
    "    'account_id': 'acct_9999',\n",
    "    'amount': 399.99,\n",
    "    'currency': 'USD',\n",
    "    'merchant': 'online_shop',\n",
    "    'description': 'large purchase at online_shop',\n",
    "}\n",
    "# compute embedding for incoming description\n",
    "q_vec = embedder.encode([incoming['description']], convert_to_numpy=True)[0].astype('float32')\n",
    "print(q_vec)\n",
    "topk = retrieve_topk_safe(q_vec, k=5, con=con, embeddings_table=\"embeddings\")\n",
    "print(\"topk:\", topk)\n",
    "\n",
    "# assemble a RAG prompt (simple template)\n",
    "retrieved_texts = []\n",
    "for txid, score in topk:\n",
    "    row = con.execute(\"SELECT tx_id, account_id, amount, merchant, description FROM transactions WHERE tx_id = ?\", (txid,)).fetchdf()\n",
    "    if len(row) > 0:\n",
    "        r = row.iloc[0]\n",
    "        retrieved_texts.append(f\"- {r.tx_id} | {r.merchant} | ${r.amount:.2f} | {r.description}\")\n",
    "\n",
    "prompt = f\"You are a fraud analyst assistant. Given the incoming transaction and similar historical transactions, output JSON with fields: {json.dumps({'risk_score':'float 0..1','explanation':'string','evidence_tx_ids':'list'})}.\\n\\n\"\n",
    "prompt += \"Incoming transaction:\\n\"\n",
    "prompt += f\"{incoming['tx_id']} | {incoming['merchant']} | ${incoming['amount']:.2f} | {incoming['description']}\\n\\n\"\n",
    "prompt += \"Retrieved similar historical transactions:\\n\"\n",
    "prompt += \"\\n\".join(retrieved_texts)\n",
    "prompt += \"\\n\\nReturn only valid JSON.\"\n",
    "\n",
    "print('\\nPrompt preview:\\n', prompt[:1000])\n",
    "\n",
    "# Call Ollama with retry logic\n",
    "max_retries = 3\n",
    "retry_delay = 5\n",
    "timeout = 180  # Increase timeout to 3 minutes\n",
    "\n",
    "for attempt in range(max_retries):\n",
    "    try:\n",
    "        resp = call_ollama(OLLAMA_MODEL, prompt, temperature=0.0, timeout=timeout)\n",
    "        print('Ollama call latency (ms):', resp['latency_ms'])\n",
    "        break\n",
    "    except requests.exceptions.ReadTimeout:\n",
    "        if attempt < max_retries - 1:\n",
    "            wait_time = retry_delay * (2 ** attempt)\n",
    "            print(f'Timeout on attempt {attempt + 1}/{max_retries}. Retrying in {wait_time}s...')\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f'Failed after {max_retries} attempts. Generating fallback response.')\n",
    "            resp = {\n",
    "                'llm_provider': 'ollama_local',\n",
    "                'llm_model': OLLAMA_MODEL,\n",
    "                'llm_response_raw': '{\"risk_score\": 0.5, \"explanation\": \"Timeout - unable to analyze\", \"evidence_tx_ids\": []}',\n",
    "                'llm_response_json': None,\n",
    "                'latency_ms': timeout * 1000,\n",
    "                'prompt_hash': prompt_hash(prompt),\n",
    "                'call_id': str(uuid.uuid4())\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f'Error calling Ollama: {e}')\n",
    "        if attempt < max_retries - 1:\n",
    "            wait_time = retry_delay * (2 ** attempt)\n",
    "            print(f'Retrying in {wait_time}s...')\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "# Try to parse JSON from response\n",
    "parsed = try_parse_json(resp['llm_response_raw'])\n",
    "risk_score = None\n",
    "evidence = None\n",
    "if parsed and isinstance(parsed, dict):\n",
    "    risk_score = parsed.get('risk_score')\n",
    "    evidence = parsed.get('evidence_tx_ids')\n",
    "else:\n",
    "    # if response not JSON, keep raw text\n",
    "    parsed = {'text': resp['llm_response_raw']}\n",
    "\n",
    "# Persist into llm_results\n",
    "row_id = resp['call_id']\n",
    "\n",
    "# Extract transaction IDs from topk results\n",
    "retrieved_ids = [txid for txid, score in topk]\n",
    "\n",
    "provenance = {\n",
    "    'emb_model': embed_model_name,\n",
    "    'index_backend': ann_backend,\n",
    "    'retrieved': retrieved_ids\n",
    "}\n",
    "con.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO llm_results (id, tx_id, llm_model, llm_provider, llm_prompt_hash, llm_prompt, llm_response, parsed_response, risk_score, evidence_tx_ids, call_latency_ms, provenance)\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\",\n",
    "    (\n",
    "        row_id,\n",
    "        incoming['tx_id'],\n",
    "        resp['llm_model'],\n",
    "        resp['llm_provider'],\n",
    "        resp['prompt_hash'],\n",
    "        prompt if os.environ.get('STORE_PROMPTS','1')=='1' else None,\n",
    "        resp['llm_response_raw'],\n",
    "        json.dumps(parsed),\n",
    "        float(risk_score) if risk_score is not None else None,\n",
    "        json.dumps(evidence) if evidence is not None else json.dumps(retrieved_ids),\n",
    "        int(resp['latency_ms']),\n",
    "        json.dumps(provenance)\n",
    "    )\n",
    ")\n",
    "print('Inserted llm_results id=', row_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tx_id</th>\n",
       "      <th>llm_model</th>\n",
       "      <th>llm_provider</th>\n",
       "      <th>risk_score</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65f50de2-c08e-409a-bdff-a7e0f1b50c63</td>\n",
       "      <td>tx_live_0001</td>\n",
       "      <td>olmo-3</td>\n",
       "      <td>ollama_local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026-01-09 14:55:58.344965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93b0a2e5-8a25-4a9c-b59b-0fd6cbe9d9ce</td>\n",
       "      <td>tx_live_0001</td>\n",
       "      <td>olmo-3</td>\n",
       "      <td>ollama_local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026-01-08 15:31:46.163460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ea39f16f-25f5-414a-9f94-5e362757bee3</td>\n",
       "      <td>tx_live_0001</td>\n",
       "      <td>olmo-3</td>\n",
       "      <td>ollama_local</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2026-01-08 11:31:50.519013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id         tx_id llm_model  llm_provider  \\\n",
       "0  65f50de2-c08e-409a-bdff-a7e0f1b50c63  tx_live_0001    olmo-3  ollama_local   \n",
       "1  93b0a2e5-8a25-4a9c-b59b-0fd6cbe9d9ce  tx_live_0001    olmo-3  ollama_local   \n",
       "2  ea39f16f-25f5-414a-9f94-5e362757bee3  tx_live_0001    olmo-3  ollama_local   \n",
       "\n",
       "   risk_score                 created_at  \n",
       "0         NaN 2026-01-09 14:55:58.344965  \n",
       "1         NaN 2026-01-08 15:31:46.163460  \n",
       "2         NaN 2026-01-08 11:31:50.519013  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##con.execute('DETACH fraud_poc.duckdb');\n",
    "# Inspect persisted LLM results\n",
    "df_llm = con.execute('SELECT id, tx_id, llm_model, llm_provider, risk_score, created_at FROM llm_results ORDER BY created_at DESC LIMIT 10').df()\n",
    "df_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps / notes:\n",
    "- Tune prompt templates and JSON schema enforcement for robust parsing.\n",
    "- Add retries, timeouts, and fallback for Ollama calls in production tasks.\n",
    "- Move index persistence to a vector DB (Milvus/Weaviate) when scaling beyond a single node.\n",
    "- Mask PII consistently and store PII mappings in a secure vault (HashiCorp Vault) if required.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
