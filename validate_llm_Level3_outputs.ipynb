{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_calls: 201\n",
      "__OLLAMA_ERROR__ count: 200\n",
      "parseable JSON: 1 objects: 1 arrays: 0 non-JSON/failed: 200\n",
      "\\nExamples of non-JSON/raw outputs (up to 5):\n",
      "index=0: __OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details: cmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out cmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\" cmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')\\n\n",
      "index=1: __OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details: cmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out cmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\" cmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')\\n\n",
      "index=2: __OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details: cmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out cmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\" cmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')\\n\n",
      "index=3: __OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details: cmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out cmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\" cmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')\\n\n",
      "index=4: __OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details: cmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out cmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\" cmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')\\n\n",
      "\\nFirst 5 raw outputs (full lines):\n",
      "{\n",
      "  \"transaction_id\": \"T100000\",\n",
      "  \"timestamp_utc\": \"2026-01-25T13:51:14.544123+00:00\",\n",
      "  \"prompt\": \"<batched prompt; batch_size=4>\",\n",
      "  \"raw_output\": \"__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\\\ncmd=[\\\\'ollama\\\\', \\\\'run\\\\', \\\\'llama2\\\\'] rc=timeout err=command timed out\\\\ncmd=[\\\\'ollama\\\\', \\\\'generate\\\\', \\\\'llama2\\\\', \\\\'--temperature\\\\', \\\\'0\\\\'] rc=1 err=Error: unknown command \\\"generate\\\" for \\\"ollama\\\"\\\\ncmd=[\\\\'ollama\\\\', \\\\'chat\\\\', \\\\'llama2\\\\', \\\\'--no-stream\\\\'] rc=1 err=Error: unknown command \\\"chat\\\" for \\\"ollama\\\"')\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.046048402786255\n",
      "}\n",
      "{\n",
      "  \"transaction_id\": \"T100001\",\n",
      "  \"timestamp_utc\": \"2026-01-25T13:51:14.544495+00:00\",\n",
      "  \"prompt\": \"<batched prompt; batch_size=4>\",\n",
      "  \"raw_output\": \"__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\\\ncmd=[\\\\'ollama\\\\', \\\\'run\\\\', \\\\'llama2\\\\'] rc=timeout err=command timed out\\\\ncmd=[\\\\'ollama\\\\', \\\\'generate\\\\', \\\\'llama2\\\\', \\\\'--temperature\\\\', \\\\'0\\\\'] rc=1 err=Error: unknown command \\\"generate\\\" for \\\"ollama\\\"\\\\ncmd=[\\\\'ollama\\\\', \\\\'chat\\\\', \\\\'llama2\\\\', \\\\'--no-stream\\\\'] rc=1 err=Error: unknown command \\\"chat\\\" for \\\"ollama\\\"')\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.046048402786255\n",
      "}\n",
      "{\n",
      "  \"transaction_id\": \"T100002\",\n",
      "  \"timestamp_utc\": \"2026-01-25T13:51:14.544696+00:00\",\n",
      "  \"prompt\": \"<batched prompt; batch_size=4>\",\n",
      "  \"raw_output\": \"__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\\\ncmd=[\\\\'ollama\\\\', \\\\'run\\\\', \\\\'llama2\\\\'] rc=timeout err=command timed out\\\\ncmd=[\\\\'ollama\\\\', \\\\'generate\\\\', \\\\'llama2\\\\', \\\\'--temperature\\\\', \\\\'0\\\\'] rc=1 err=Error: unknown command \\\"generate\\\" for \\\"ollama\\\"\\\\ncmd=[\\\\'ollama\\\\', \\\\'chat\\\\', \\\\'llama2\\\\', \\\\'--no-stream\\\\'] rc=1 err=Error: unknown command \\\"chat\\\" for \\\"ollama\\\"')\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.046048402786255\n",
      "}\n",
      "{\n",
      "  \"transaction_id\": \"T100003\",\n",
      "  \"timestamp_utc\": \"2026-01-25T13:51:14.544829+00:00\",\n",
      "  \"prompt\": \"<batched prompt; batch_size=4>\",\n",
      "  \"raw_output\": \"__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\\\ncmd=[\\\\'ollama\\\\', \\\\'run\\\\', \\\\'llama2\\\\'] rc=timeout err=command timed out\\\\ncmd=[\\\\'ollama\\\\', \\\\'generate\\\\', \\\\'llama2\\\\', \\\\'--temperature\\\\', \\\\'0\\\\'] rc=1 err=Error: unknown command \\\"generate\\\" for \\\"ollama\\\"\\\\ncmd=[\\\\'ollama\\\\', \\\\'chat\\\\', \\\\'llama2\\\\', \\\\'--no-stream\\\\'] rc=1 err=Error: unknown command \\\"chat\\\" for \\\"ollama\\\"')\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.046048402786255\n",
      "}\n",
      "{\n",
      "  \"transaction_id\": \"T100004\",\n",
      "  \"timestamp_utc\": \"2026-01-25T13:51:44.592857+00:00\",\n",
      "  \"prompt\": \"<batched prompt; batch_size=4>\",\n",
      "  \"raw_output\": \"__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\\\ncmd=[\\\\'ollama\\\\', \\\\'run\\\\', \\\\'llama2\\\\'] rc=timeout err=command timed out\\\\ncmd=[\\\\'ollama\\\\', \\\\'generate\\\\', \\\\'llama2\\\\', \\\\'--temperature\\\\', \\\\'0\\\\'] rc=1 err=Error: unknown command \\\"generate\\\" for \\\"ollama\\\"\\\\ncmd=[\\\\'ollama\\\\', \\\\'chat\\\\', \\\\'llama2\\\\', \\\\'--no-stream\\\\'] rc=1 err=Error: unknown command \\\"chat\\\" for \\\"ollama\\\"')\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.04761838912964\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib, itertools\n",
    "p=pathlib.Path('artifacts/level3_llm_run/llm_parsed')\n",
    "if not p.exists():\n",
    "    print(\"MISSING:\", p); raise SystemExit(1)\n",
    "lines=[json.loads(l) for l in p.read_text().splitlines() if l.strip()]\n",
    "total=len(lines)\n",
    "raws=[l.get('raw_output','') for l in lines]\n",
    "cnt_ollama_err=sum(1 for r in raws if isinstance(r,str) and r.startswith('__OLLAMA_ERROR__'))\n",
    "parseable=0; objs=0; arrays=0; nonparse=[]\n",
    "for i,r in enumerate(raws):\n",
    "    if not isinstance(r,str):\n",
    "        nonparse.append((i,str(type(r))))\n",
    "        continue\n",
    "    try:\n",
    "        parsed=json.loads(r)\n",
    "        parseable+=1\n",
    "        if isinstance(parsed, list):\n",
    "            arrays+=1\n",
    "        elif isinstance(parsed, dict):\n",
    "            objs+=1\n",
    "    except Exception:\n",
    "        nonparse.append((i, (r[:400].replace('\\\\n',' ').replace('\\\\r',' '))))\n",
    "print(\"total_calls:\", total)\n",
    "print(\"__OLLAMA_ERROR__ count:\", cnt_ollama_err)\n",
    "print(\"parseable JSON:\", parseable, \"objects:\", objs, \"arrays:\", arrays, \"non-JSON/failed:\", len(nonparse))\n",
    "print(\"\\\\nExamples of non-JSON/raw outputs (up to 5):\")\n",
    "for i,s in itertools.islice(nonparse,5):\n",
    "    print(f\"index={i}: {s}\\\\n\")\n",
    "print(\"\\\\nFirst 5 raw outputs (full lines):\")\n",
    "for l in lines[:5]:\n",
    "    print(json.dumps(l, indent=2)[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c11e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 100\n",
      "llm_adjustment_valid: 0\n",
      "needs_review: 100\n",
      "non-zero clamped: 0\n",
      "count    100.0\n",
      "mean       0.0\n",
      "std        0.0\n",
      "min        0.0\n",
      "25%        0.0\n",
      "50%        0.0\n",
      "75%        0.0\n",
      "max        0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "p='artifacts/level3_llm_run/llm_parsed.parquet' \n",
    "df=pd.read_parquet(p)\n",
    "print(\"rows:\", len(df))\n",
    "print(\"llm_adjustment_valid:\", int(df['llm_adjustment_valid'].sum()))\n",
    "print(\"needs_review:\", int(df['needs_review'].sum()))\n",
    "print(\"non-zero clamped:\", int((df['llm_adjustment_clamped']!=0).sum()))\n",
    "print(df['llm_adjustment_clamped'].describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29d3671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX 100\n",
      "{\n",
      "  \"transaction_id\": \"WARMUP\",\n",
      "  \"timestamp_utc\": \"2026-01-25T16:15:30.880384+00:00\",\n",
      "  \"prompt\": \"<warmup prompt>\",\n",
      "  \"raw_output\": \"{\\n  \\\"transaction_id\\\": \\\"WARMUP\\\",\\n  \\\"llm_adjustment\\\": 0.0,\\n  \\\"evidence_ids\\\": [\\\"E1\\\"],\\n  \\\"explanation\\\": \\\"baseline=0.0000\\\",\\n  \\\"confidence\\\": null\\n}\\n\\n\",\n",
      "  \"model\": \"llama2\",\n",
      "  \"elapsed_seconds\": 30.193673133850098\n",
      "}\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import json, pathlib\n",
    "p=pathlib.Path('artifacts/level3_llm_run/llm_raw.jsonl')\n",
    "for i,l in enumerate(p.read_text().splitlines()):\n",
    "    j=json.loads(l)\n",
    "    ro=j.get('raw_output','')\n",
    "    if isinstance(ro,str) and not ro.startswith('__OLLAMA_ERROR__'):\n",
    "        print(\"INDEX\",i)\n",
    "        print(json.dumps(j, indent=2, ensure_ascii=False))\n",
    "        break\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec402c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WROTE artifacts/results_stream_with_llm.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "res = pd.read_parquet('artifacts/results_stream.parquet') \n",
    "llm = pd.read_parquet('artifacts/level3_llm_run/llm_parsed.parquet') \n",
    "res['transaction_id']=res['transaction_id'].astype(str) \n",
    "llm['transaction_id']=llm['transaction_id'].astype(str) \n",
    "llm_sel = llm[['transaction_id','llm_adjustment_clamped','llm_adjustment_raw','llm_adjustment_valid','llm_evidence_ids','needs_review']].copy() \n",
    "merged = res.merge(llm_sel, on='transaction_id', how='left') \n",
    "merged['llm_adjustment_clamped'] = merged['llm_adjustment_clamped'].fillna(0.0) \n",
    "merged['llm_adjustment_valid'] = merged['llm_adjustment_valid'].fillna(False) \n",
    "merged.to_parquet('artifacts/results_stream_with_llm.parquet', index=False) \n",
    "print(\"WROTE artifacts/results_stream_with_llm.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
