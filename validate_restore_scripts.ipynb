{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7189cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote baseline-only outputs: 5000000\n",
      "allow    5000000\n",
      "Name: decision, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "p='artifacts/results_stream.parquet'\n",
    "df = pd.read_parquet(p)\n",
    "df['final_score'] = df['baseline_score']\n",
    "df['decision'] = df['final_score'].apply(lambda s: 'block' if s>=0.9 else ('review' if s>=0.6 else 'allow'))\n",
    "df.to_parquet('artifacts/results_stream_baseline_only.parquet', index=False)\n",
    "df.to_csv('artifacts/results_stream_baseline_only.csv', index=False)\n",
    "print(\"Wrote baseline-only outputs:\", len(df))\n",
    "print(df['decision'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12125745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 5000000\n",
      "baseline_score quantiles: {0.0: 0.0, 0.01: 0.0, 0.1: 0.0, 0.5: 0.0435471546350291, 0.9: 0.0451618229854689, 0.99: 0.046326626111371, 1.0: 0.0655737704918032}\n",
      "max baseline_score: 0.0655737704918032\n",
      "count baseline>=0.9: 0\n",
      "count baseline>=0.6: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_parquet('artifacts/results_stream_baseline_only.parquet') \n",
    "print(\"rows:\", len(df)) \n",
    "print(\"baseline_score quantiles:\", df['baseline_score'].quantile([0,0.01,0.1,0.5,0.9,0.99,1]).to_dict()) \n",
    "print(\"max baseline_score:\", df['baseline_score'].max()) \n",
    "print(\"count baseline>=0.9:\", int((df['baseline_score'] >= 0.9).sum())) \n",
    "print(\"count baseline>=0.6:\", int((df['baseline_score'] >= 0.6).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c656f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote review-only alerts at threshold: 0.0451618229854689\n",
      "TP in top500k: 30849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, duckdb \n",
    "df = pd.read_parquet('artifacts/results_stream_baseline_only.parquet') \n",
    "k_alert = 500_000 \n",
    "sorted_scores = df['baseline_score'].sort_values(ascending=False).reset_index(drop=True) \n",
    "thr_alert = float(sorted_scores.iloc[k_alert-1]) \n",
    "df['decision'] = df['baseline_score'].apply(lambda s: 'review' \n",
    "if s >= thr_alert else 'allow') \n",
    "out_pq = 'artifacts/results_stream_alerts_500k_review_only.parquet' \n",
    "out_csv = 'artifacts/results_stream_alerts_500k_review_only.csv'\n",
    "df.to_parquet(out_pq, index=False) \n",
    "df.to_csv(out_csv, index=False) \n",
    "print(\"Wrote review-only alerts at threshold:\", thr_alert) \n",
    "q = f\"\"\" SELECT COUNT(*) AS tp FROM ( SELECT transaction_id FROM '{out_pq}' ORDER BY baseline_score DESC LIMIT 500000 ) r JOIN 'financial_fraud_detection_dataset.csv' o USING (transaction_id) WHERE o.is_fraud = TRUE; \"\"\" \n",
    "print(\"TP in top500k:\", duckdb.query(q).fetchdf()['tp'].iloc[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d7f2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k, threshold, TP, precision\n",
      "50, 0.06557377, 48, 0.960000\n",
      "100, 0.06557377, 5, 0.050000\n",
      "500, 0.06557377, 144, 0.288000\n",
      "1000, 0.06557377, 298, 0.298000\n",
      "5000, 0.04632663, 1729, 0.345800\n",
      "10000, 0.04632663, 1954, 0.195400\n",
      "50000, 0.04632663, 6509, 0.130180\n",
      "100000, 0.04632663, 12099, 0.120990\n",
      "500000, 0.04516182, 30849, 0.061698\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, duckdb \n",
    "dfp = 'artifacts/results_stream_baseline_only.parquet' \n",
    "df = pd.read_parquet(dfp) \n",
    "ks = [50,100,500,1000,5000,10000,50000,100000,500000] \n",
    "print(\"k, threshold, TP, precision\") \n",
    "for k in ks: \n",
    "    thr = float(df['baseline_score'].sort_values(ascending=False).iloc[k-1]) \n",
    "    tp = duckdb.query(f\"\"\" SELECT COUNT(*) AS tp FROM ( SELECT transaction_id FROM '{dfp}' ORDER BY baseline_score DESC LIMIT {k} ) r JOIN 'financial_fraud_detection_dataset.csv' o USING(transaction_id) WHERE o.is_fraud = TRUE \"\"\").fetchdf()['tp'].iloc[0] \n",
    "    print(f\"{k}, {thr:.8f}, {tp}, {tp/k:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c864f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote deterministic review-only top500k at thr: 0.0451618229854689\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "k_alert = 500_000 \n",
    "df = pd.read_parquet('artifacts/results_stream_baseline_only.parquet') \n",
    "df_sorted = df.sort_values(['baseline_score','transaction_id'], ascending=[False, True]).reset_index(drop=True) \n",
    "thr_alert = float(df_sorted['baseline_score'].iloc[k_alert-1]) \n",
    "df['decision'] = df['baseline_score'].apply(lambda s: 'review' \n",
    "if s >= thr_alert else 'allow') \n",
    "df.to_parquet('artifacts/results_stream_alerts_500k_review_only_deterministic.parquet', index=False) \n",
    "df.to_csv('artifacts/results_stream_alerts_500k_review_only_deterministic.csv', index=False) \n",
    "print(\"Wrote deterministic review-only top500k at thr:\", thr_alert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9819a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_parquet('artifacts/results_stream_baseline_only.parquet')\n",
    "df_sorted = df.sort_values(['baseline_score','transaction_id'], ascending=[False, True]).reset_index(drop=True) \n",
    "k_alert = 500000 \n",
    "k_block = 50 \n",
    "thr_block = float(df_sorted['baseline_score'].iloc[k_block-1]) \n",
    "thr_alert = float(df_sorted['baseline_score'].iloc[k_alert-1]) \n",
    "def decide(s): \n",
    "    if s >= thr_block: \n",
    "        return 'block' \n",
    "    elif s >= thr_alert: \n",
    "        return 'review' \n",
    "    else: \n",
    "        return 'allow' \n",
    "    df['decision'] = df['baseline_score'].apply(decide) \n",
    "    df.to_parquet('artifacts/results_stream_alerts_500k_block50.parquet', index=False) \n",
    "    df.to_csv('artifacts/results_stream_alerts_500k_block50.csv', index=False) \n",
    "    print(\"Wrote block50 + review500k; thresholds:\", thr_block, thr_alert) \n",
    "    print(df['decision'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e939dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[guard] anomaly median=0.922 > 0.6 — forcing combine_mode='baseline'\n"
     ]
    }
   ],
   "source": [
    "# --- Guard: force baseline combine if anomaly median is suspiciously high ---\n",
    "import os\n",
    "\n",
    "# configurable via env var (default 0.6)\n",
    "_guard_th = os.getenv('ANOM_MEDIAN_GUARD', '0.6')\n",
    "try:\n",
    "    guard_threshold = float(_guard_th)\n",
    "except Exception:\n",
    "    guard_threshold = 0.6\n",
    "\n",
    "# attempt to compute anomaly median from the DataFrame used for recombine.\n",
    "# common names: df_all, df_results, results_df — try a few fallbacks\n",
    "anom_median = None\n",
    "for candidate_df_name in ('df_all', 'results_df', 'df_results', 'df'):\n",
    "    try:\n",
    "        candidate = globals().get(candidate_df_name)\n",
    "        if candidate is not None and 'anomaly_score' in candidate.columns:\n",
    "            anom_median = float(candidate['anomaly_score'].median())\n",
    "            break\n",
    "    except Exception:\n",
    "        anom_median = None\n",
    "\n",
    "# As a last resort, try to read a recent artifacts file (non-blocking)\n",
    "if anom_median is None:\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        if os.path.exists('artifacts/results_stream.parquet'):\n",
    "            tmp = pd.read_parquet('artifacts/results_stream.parquet', columns=['anomaly_score'])\n",
    "            anom_median = float(tmp['anomaly_score'].median())\n",
    "        elif os.path.exists('artifacts/results_stream.csv'):\n",
    "            tmp = pd.read_csv('artifacts/results_stream.csv', usecols=['anomaly_score'])\n",
    "            anom_median = float(tmp['anomaly_score'].median())\n",
    "    except Exception:\n",
    "        anom_median = None\n",
    "\n",
    "if anom_median is not None and anom_median > guard_threshold:\n",
    "    print(f\"[guard] anomaly median={anom_median:.3f} > {guard_threshold} — forcing combine_mode='baseline'\")\n",
    "    # modify args if present, otherwise set local variable used by recombine\n",
    "    try:\n",
    "        args.combine_mode = 'baseline'\n",
    "    except Exception:\n",
    "        try:\n",
    "            chosen_combine_mode = 'baseline'\n",
    "        except Exception:\n",
    "            pass\n",
    "    # write an artifact flag so ops/monitoring can detect guard triggers\n",
    "    try:\n",
    "        with open('artifacts/guard_triggered.txt', 'w') as fh:\n",
    "            fh.write(f'anom_median={anom_median:.6f}, threshold={guard_threshold}\\n')\n",
    "    except Exception:\n",
    "        pass\n",
    "# ------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "831432dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['transaction_id', 'timestamp', 'sender_account', 'receiver_account', 'amount', 'transaction_type', 'merchant_category', 'location', 'device_used', 'is_fraud', 'fraud_type', 'time_since_last_transaction', 'spending_deviation_score', 'velocity_score', 'geo_anomaly_score', 'payment_channel', 'ip_address', 'device_hash']\n",
      "{'transaction_id': dtype('O'), 'timestamp': dtype('O'), 'sender_account': dtype('O'), 'receiver_account': dtype('O'), 'amount': dtype('float64'), 'transaction_type': dtype('O'), 'merchant_category': dtype('O'), 'location': dtype('O'), 'device_used': dtype('O'), 'is_fraud': dtype('bool'), 'fraud_type': dtype('float64'), 'time_since_last_transaction': dtype('float64'), 'spending_deviation_score': dtype('float64'), 'velocity_score': dtype('int64'), 'geo_anomaly_score': dtype('float64'), 'payment_channel': dtype('O'), 'ip_address': dtype('O'), 'device_hash': dtype('O')}\n",
      "\n",
      "first rows:\n",
      " transaction_id                  timestamp sender_account receiver_account  amount transaction_type merchant_category location device_used  is_fraud  fraud_type  time_since_last_transaction  spending_deviation_score  velocity_score  geo_anomaly_score payment_channel      ip_address device_hash\n",
      "       T100000 2023-08-22T09:22:43.516168      ACC877572        ACC388389  343.78       withdrawal         utilities    Tokyo      mobile     False         NaN                          NaN                     -0.21               3               0.22            card  13.101.214.112    D8536477\n",
      "       T100001 2023-08-04T01:58:02.606711      ACC895667        ACC944962  419.65       withdrawal            online  Toronto         atm     False         NaN                          NaN                     -0.14               7               0.96             ACH   172.52.47.194    D2622631\n",
      "       T100002 2023-05-12T11:39:33.742963      ACC733052        ACC377370 2773.86          deposit             other   London         pos     False         NaN                          NaN                     -1.78              20               0.89            card    185.98.35.23    D4823498\n",
      "       T100003 2023-10-10T06:04:43.195112      ACC996865        ACC344098 1666.22          deposit            online   Sydney         pos     False         NaN                          NaN                     -0.60               6               0.37   wire_transfer   107.136.36.87    D9961380\n",
      "       T100004 2023-09-24T08:09:02.700162      ACC584714        ACC497887   24.43         transfer         utilities  Toronto      mobile     False         NaN                          NaN                      0.79              13               0.27             ACH 108.161.108.255    D7637601\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('financial_fraud_detection_dataset.csv', nrows=5) \n",
    "print(\"columns:\", df.columns.tolist()) \n",
    "print(df.dtypes.to_dict()) \n",
    "print(\"\\nfirst rows:\\n\", df.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe49053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amount,fraud_type,time_since_last_transaction,spending_deviation_score,velocity_score,geo_anomaly_score\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('financial_fraud_detection_dataset.csv', nrows=1000) \n",
    "cols = [c for c in df.select_dtypes(include=['number']).columns if c != 'transaction_id'] \n",
    "print(','.join(cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c45d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest p1,p99: 0.42115231571845724 0.6269080576836324\n",
      "raw metric summary:\n",
      " count    2000.000000\n",
      "mean        0.488622\n",
      "std         0.045754\n",
      "min         0.415034\n",
      "25%         0.454074\n",
      "50%         0.481693\n",
      "75%         0.514196\n",
      "max         0.698280\n",
      "Name: raw_isof_score, dtype: float64\n",
      "anomaly_score quantiles:\n",
      " {0.0: 0.0, 0.01: 3.5829746331111693e-06, 0.5: 0.29423407960382386, 0.99: 0.9999413239835215, 1.0: 1.0}\n",
      "fraction anomaly_score > 0.5: 0.1955\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "m = json.load(open('artifacts/level2_isof/manifest.json'))\n",
    "print(\"manifest p1,p99:\", m.get('p1'), m.get('p99'))\n",
    "raw = pd.read_parquet('artifacts/level2_isof/raw_scores.parquet')\n",
    "print(\"raw metric summary:\\n\", raw.iloc[:,1].describe())\n",
    "anom = pd.read_parquet('artifacts/level2_isof/anomaly_scores.parquet')\n",
    "print(\"anomaly_score quantiles:\\n\", anom['anomaly_score'].quantile([0.0,0.01,0.5,0.99,1.0]).to_dict())\n",
    "print(\"fraction anomaly_score > 0.5:\", (anom['anomaly_score'] > 0.5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d2125df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists: True\n",
      "rows: 5000000\n",
      "columns: ['transaction_id', 'baseline_score', 'anomaly_score_x', 'llm_adjustment', 'final_score', 'decision', 'anomaly_score_y', 'llm_evidence_ids', 'topk_evidence_ids', 'llm_adjustment_valid', 'llm_adjustment_clamped']\n",
      "final==baseline all?: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, os\n",
    "p='artifacts/results_stream_recombined.parquet'\n",
    "print(\"exists:\", os.path.exists(p))\n",
    "if os.path.exists(p):\n",
    "    df=pd.read_parquet(p)\n",
    "    print(\"rows:\", len(df))\n",
    "    print(\"columns:\", df.columns.tolist())\n",
    "    if 'final_score' in df.columns and 'baseline_score' in df.columns:\n",
    "        print(\"final==baseline all?:\", (df['final_score']==df['baseline_score']).all())\n",
    "    if 'anomaly_score' in df.columns:\n",
    "        print(\"anomaly_score median:\", float(df['anomaly_score'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d34029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manifest p1,p99: 0.39893067927202036 0.6375998816089603\n",
      "raw metric quantiles:\n",
      " {0.0: 0.3887290595292977, 0.01: 0.39893067927202036, 0.1: 0.4121032179585345, 0.5: 0.4557627288236442, 0.9: 0.5629627460461307, 0.99: 0.6375998816089603, 1.0: 0.757819854954771}\n",
      "anomaly_score quantiles:\n",
      " {0.0: 0.0, 0.01: 6.478815355932801e-08, 0.5: 0.23812058277796372, 0.9: 0.6872778941228411, 0.99: 0.9999964522586751, 1.0: 1.0}\n",
      "fraction anomaly_score > 0.95: 0.01445\n",
      "median anomaly_score: 0.23812058277796372\n"
     ]
    }
   ],
   "source": [
    "import json, pandas as pd\n",
    "m = json.load(open('artifacts/level2_isof_recomputed/manifest.json'))\n",
    "print(\"manifest p1,p99:\", m.get('p1'), m.get('p99'))\n",
    "raw = pd.read_parquet('artifacts/level2_isof_recomputed/raw_scores.parquet')\n",
    "print(\"raw metric quantiles:\\n\", raw.iloc[:,1].quantile([0.0,0.01,0.1,0.5,0.9,0.99,1.0]).to_dict())\n",
    "anom = pd.read_parquet('artifacts/level2_isof_recomputed/anomaly_scores.parquet')\n",
    "print(\"anomaly_score quantiles:\\n\", anom['anomaly_score'].quantile([0.0,0.01,0.5,0.9,0.99,1.0]).to_dict())\n",
    "print(\"fraction anomaly_score > 0.95:\", (anom['anomaly_score'] > 0.95).mean())\n",
    "print(\"median anomaly_score:\", float(anom['anomaly_score'].median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e263b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 5000000\n",
      "rows where final != baseline: 0\n",
      "fraction influenced: 0.0\n",
      "top positive deltas:\n",
      " transaction_id  baseline_score  final_score_after  delta\n",
      "       T100000        0.000000           0.000000    0.0\n",
      "      T3433331        0.043547           0.043547    0.0\n",
      "      T3433338        0.043547           0.043547    0.0\n",
      "      T3433337        0.043547           0.043547    0.0\n",
      "      T3433336        0.043547           0.043547    0.0\n",
      "      T3433335        0.043547           0.043547    0.0\n",
      "      T3433334        0.043547           0.043547    0.0\n",
      "      T3433333        0.043547           0.043547    0.0\n",
      "      T3433332        0.043547           0.043547    0.0\n",
      "      T3433330        0.043547           0.043547    0.0\n",
      "top negative deltas:\n",
      " transaction_id  baseline_score  final_score_after  delta\n",
      "       T100000        0.000000           0.000000    0.0\n",
      "      T3433337        0.043547           0.043547    0.0\n",
      "      T3433336        0.043547           0.043547    0.0\n",
      "      T3433335        0.043547           0.043547    0.0\n",
      "      T3433334        0.043547           0.043547    0.0\n",
      "      T3433333        0.043547           0.043547    0.0\n",
      "      T3433332        0.043547           0.043547    0.0\n",
      "      T3433331        0.043547           0.043547    0.0\n",
      "      T3433330        0.043547           0.043547    0.0\n",
      "      T3433329        0.043547           0.043547    0.0\n"
     ]
    }
   ],
   "source": [
    "# Use the already defined variable p for the recombined file\n",
    "before = pd.read_parquet('artifacts/results_stream.parquet')\n",
    "after = pd.read_parquet(p)\n",
    "# join on transaction_id (assumes same index/rows)\n",
    "df = before.merge(after[['transaction_id','final_score']], on='transaction_id', suffixes=('_before','_after'))\n",
    "df['delta'] = df['final_score_after'] - df['baseline_score']\n",
    "print(\"rows:\", len(df))\n",
    "print(\"rows where final != baseline:\", (df['final_score_after'] != df['baseline_score']).sum())\n",
    "print(\"fraction influenced:\", (df['final_score_after'] != df['baseline_score']).mean())\n",
    "print(\"top positive deltas:\\n\", df.sort_values('delta', ascending=False).head(10)[['transaction_id','baseline_score','final_score_after','delta']].to_string(index=False))\n",
    "print(\"top negative deltas:\\n\", df.sort_values('delta').head(10)[['transaction_id','baseline_score','final_score_after','delta']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ce96c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results file: True artifacts/results_stream.parquet\n",
      "anomaly candidate picks: ['artifacts/level2_isof/anomaly_scores.parquet', 'artifacts/level2_isof_v20260124124228/anomaly_scores.parquet', 'artifacts/level2_isof_recomputed/anomaly_scores.parquet']\n",
      "using anomaly: artifacts/level2_isof/anomaly_scores.parquet exists: True\n",
      "\n",
      "results columns: ['transaction_id', 'baseline_score', 'anomaly_score', 'llm_adjustment', 'final_score', 'decision']\n",
      "anomaly columns: ['transaction_id', 'anomaly_score']\n",
      "\n",
      "Sample transaction_ids (results): ['T100000', 'T100001', 'T100002', 'T100003', 'T100004']\n",
      "Sample transaction_ids (anom): ['T100000', 'T100001', 'T100002', 'T100003', 'T100004']\n",
      "dtypes: object object\n",
      "\n",
      "Merged shape: (5000000, 7)\n",
      "Count anomaly_score notnull after merge: 5000000 of 5000000\n",
      "fraction anomaly_score null: 0.0\n",
      "baseline < 0.2 count: 5000000\n",
      "baseline<gate & anomaly present: 5000000\n",
      "\n",
      "Top merged rows where baseline<gate but anomaly is null (show a few):\n",
      "Empty DataFrame\n",
      "Columns: [transaction_id, baseline_score, anomaly_score, llm_adjustment, final_score, decision, anomaly_score_anom]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# filename: scripts/diag_level2_merge.py\n",
    "# Run: PYTHONPATH=. python scripts/diag_level2_merge.py\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "p_res = Path('artifacts/results_stream.parquet')\n",
    "# find likely anomaly artifact (adjust path if you used a different name)\n",
    "p_anom_candidates = list(Path('artifacts').glob('**/anomaly_scores*.parquet'))\n",
    "p_anom = p_anom_candidates[0] if p_anom_candidates else Path('artifacts/level2_isof/anomaly_scores.parquet')\n",
    "\n",
    "print(\"results file:\", p_res.exists(), p_res)\n",
    "print(\"anomaly candidate picks:\", [str(p) for p in p_anom_candidates])\n",
    "print(\"using anomaly:\", p_anom, \"exists:\", p_anom.exists())\n",
    "\n",
    "res = pd.read_parquet(p_res)\n",
    "an = pd.read_parquet(p_anom)\n",
    "\n",
    "print(\"\\nresults columns:\", res.columns.tolist())\n",
    "print(\"anomaly columns:\", an.columns.tolist())\n",
    "print(\"\\nSample transaction_ids (results):\", res['transaction_id'].head(5).tolist())\n",
    "print(\"Sample transaction_ids (anom):\", an['transaction_id'].head(5).tolist())\n",
    "print(\"dtypes:\", res['transaction_id'].dtype, an['transaction_id'].dtype)\n",
    "\n",
    "merged = res.merge(an, on='transaction_id', how='left', suffixes=('','_anom'))\n",
    "print(\"\\nMerged shape:\", merged.shape)\n",
    "print(\"Count anomaly_score notnull after merge:\", merged.get('anomaly_score', merged.get('anomaly_score_anom')).notna().sum(), \"of\", len(merged))\n",
    "print(\"fraction anomaly_score null:\", merged.get('anomaly_score', merged.get('anomaly_score_anom')).isna().mean())\n",
    "\n",
    "# gate diagnostics (use gate 0.20)\n",
    "gate = 0.20\n",
    "mask_base_low = merged['baseline_score'] < gate\n",
    "print(f\"baseline < {gate} count:\", mask_base_low.sum())\n",
    "print(\"baseline<gate & anomaly present:\", ((mask_base_low) & merged.get('anomaly_score', merged.get('anomaly_score_anom')).notna()).sum())\n",
    "\n",
    "print(\"\\nTop merged rows where baseline<gate but anomaly is null (show a few):\")\n",
    "print(merged.loc[(mask_base_low)&merged.get('anomaly_score', merged.get('anomaly_score_anom')).isna()].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dab0fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results: rows 5000000\n",
      "results.anomaly_score dtype: float64\n",
      "results.anomaly_score not-null: 5000000 null: 0\n",
      "results.anom quantiles: {0.0: 0.0, 0.01: 0.002883526452322168, 0.1: 0.01916182418789604, 0.5: 0.9215508206289067, 0.9: 0.9607781988833756, 0.99: 1.0, 1.0: 1.0}\n",
      "\n",
      "artifact: rows 2000\n",
      "artifact.anomaly_score dtype: float64\n",
      "artifact.anomaly_score not-null: 2000 null: 0\n",
      "artifact.anom quantiles: {0.0: 0.0, 0.01: 3.5829746331111693e-06, 0.1: 0.07250616112361015, 0.5: 0.29423407960382386, 0.9: 0.6431644716512526, 0.99: 0.9999413239835215, 1.0: 1.0}\n",
      "\n",
      "artifact sample anomaly_score values (first 20):\n",
      "[0.21454713382763085, 0.3619142161417679, 1.0, 0.6451698734372677, 0.08393591256526844, 0.4089534658326943, 0.7547174108721049, 0.040989094916549805, 0.4640156722499847, 0.17752572933277636, 0.7125686910253216, 0.24199506296472278, 0.1226680351794046, 0.05140764511096533, 0.8462056704484046, 0.37846051169538103, 0.722816857637804, 0.49290286487415946, 0.08902687798943476, 0.6430994289986957]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "res = pd.read_parquet('artifacts/results_stream.parquet')\n",
    "anom = pd.read_parquet('artifacts/level2_isof/anomaly_scores.parquet')\n",
    "\n",
    "print(\"results: rows\", len(res))\n",
    "print(\"results.anomaly_score dtype:\", res['anomaly_score'].dtype)\n",
    "print(\"results.anomaly_score not-null:\", res['anomaly_score'].notna().sum(), \"null:\", res['anomaly_score'].isna().sum())\n",
    "try:\n",
    "    print(\"results.anom quantiles:\", res['anomaly_score'].quantile([0,0.01,0.1,0.5,0.9,0.99,1]).to_dict())\n",
    "except Exception as e:\n",
    "    print(\"results.anom quantile error:\", e)\n",
    "\n",
    "print(\"\\nartifact: rows\", len(anom))\n",
    "print(\"artifact.anomaly_score dtype:\", anom['anomaly_score'].dtype)\n",
    "print(\"artifact.anomaly_score not-null:\", anom['anomaly_score'].notna().sum(), \"null:\", anom['anomaly_score'].isna().sum())\n",
    "try:\n",
    "    print(\"artifact.anom quantiles:\", anom['anomaly_score'].quantile([0,0.01,0.1,0.5,0.9,0.99,1]).to_dict())\n",
    "except Exception as e:\n",
    "    print(\"artifact.anom quantile error:\", e)\n",
    "\n",
    "# sample a few raw values from artifact\n",
    "print(\"\\nartifact sample anomaly_score values (first 20):\")\n",
    "print(anom['anomaly_score'].head(20).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef68d6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 5000000\n",
      "rows where final != baseline: 0\n",
      "fraction influenced: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "before = pd.read_parquet('artifacts/results_stream.parquet')\n",
    "after = pd.read_parquet('artifacts/results_stream_recombined_test.parquet')\n",
    "print(\"rows:\", len(before))\n",
    "print(\"rows where final != baseline:\", (after['final_score'] != before['baseline_score']).sum())\n",
    "print(\"fraction influenced:\", ((after['final_score'] != before['baseline_score']).mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61128acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows: 5000000\n",
      "rows where final != baseline: 0\n",
      "fraction influenced: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "before = pd.read_parquet('artifacts/results_stream.parquet')\n",
    "after = pd.read_parquet('artifacts/results_stream_recombined_test.parquet')\n",
    "print(\"rows:\", len(before))\n",
    "print(\"rows where final != baseline:\", (after['final_score'] != before['baseline_score']).sum())\n",
    "print(\"fraction influenced:\", ((after['final_score'] != before['baseline_score']).mean()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud-poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
