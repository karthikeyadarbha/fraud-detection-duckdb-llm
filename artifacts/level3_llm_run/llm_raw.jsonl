{"transaction_id": "T100000", "timestamp_utc": "2026-01-25T13:51:14.544123+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.046048402786255}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-25T13:51:14.544495+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.046048402786255}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-25T13:51:14.544696+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.046048402786255}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-25T13:51:14.544829+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.046048402786255}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-25T13:51:44.592857+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.04761838912964}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-25T13:51:44.593063+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.04761838912964}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-25T13:51:44.593194+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.04761838912964}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-25T13:51:44.593419+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.04761838912964}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-25T13:52:14.841565+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.24775195121765}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-25T13:52:14.841739+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.24775195121765}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-25T13:52:14.841852+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.24775195121765}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-25T13:52:14.841978+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.24775195121765}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-25T13:52:44.886395+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.044115781784058}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-25T13:52:44.886607+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.044115781784058}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-25T13:52:44.886752+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.044115781784058}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-25T13:52:44.886892+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.044115781784058}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-25T13:53:14.932354+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.045169353485107}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-25T13:53:14.932566+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.045169353485107}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-25T13:53:14.932706+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.045169353485107}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-25T13:53:14.932835+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.045169353485107}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-25T13:53:44.983790+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05068063735962}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-25T13:53:44.983985+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05068063735962}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-25T13:53:44.984122+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05068063735962}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-25T13:53:44.984246+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05068063735962}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-25T13:54:15.031829+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.047295093536377}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-25T13:54:15.084563+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.047295093536377}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-25T13:54:15.084780+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.047295093536377}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-25T13:54:15.084907+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.047295093536377}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-25T13:54:45.128595+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.043349266052246}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-25T13:54:45.246661+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.043349266052246}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-25T13:54:45.246874+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.043349266052246}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-25T13:54:45.246994+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.043349266052246}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-25T13:55:15.297930+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.050654649734497}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-25T13:55:15.298125+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.050654649734497}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-25T13:55:15.298251+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.050654649734497}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-25T13:55:15.298371+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.050654649734497}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-25T13:55:45.355718+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.057014226913452}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-25T13:55:45.356094+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.057014226913452}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-25T13:55:45.356242+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.057014226913452}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-25T13:55:45.356360+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.057014226913452}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-25T13:56:15.417292+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060553789138794}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-25T13:56:15.417511+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060553789138794}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-25T13:56:15.417969+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060553789138794}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-25T13:56:15.418090+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060553789138794}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-25T13:56:45.479126+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06070613861084}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-25T13:56:45.479471+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06070613861084}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-25T13:56:45.479736+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06070613861084}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-25T13:56:45.479931+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06070613861084}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-25T13:57:15.539225+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05889344215393}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-25T13:57:15.539439+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05889344215393}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-25T13:57:15.539700+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05889344215393}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-25T13:57:15.539844+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05889344215393}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-25T13:57:45.596791+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.056588649749756}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-25T13:57:45.597243+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.056588649749756}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-25T13:57:45.597427+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.056588649749756}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-25T13:57:45.597610+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.056588649749756}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-25T13:58:15.659055+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06106996536255}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-25T13:58:15.659343+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06106996536255}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-25T13:58:15.659486+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06106996536255}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-25T13:58:15.659642+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06106996536255}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-25T13:58:45.718578+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058568477630615}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-25T13:58:45.718799+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058568477630615}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-25T13:58:45.718920+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058568477630615}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-25T13:58:45.719036+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058568477630615}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-25T13:59:15.787581+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.068180084228516}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-25T13:59:15.788118+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.068180084228516}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-25T13:59:15.788349+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.068180084228516}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-25T13:59:15.788579+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.068180084228516}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-25T13:59:45.852775+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063747882843018}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-25T13:59:45.853276+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063747882843018}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-25T13:59:45.853581+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063747882843018}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-25T13:59:45.853742+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063747882843018}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-25T14:00:15.912259+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058127403259277}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-25T14:00:15.912498+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058127403259277}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-25T14:00:15.912723+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058127403259277}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-25T14:00:15.912864+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.058127403259277}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-25T14:00:45.973273+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060065269470215}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-25T14:00:45.973487+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060065269470215}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-25T14:00:45.973757+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060065269470215}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-25T14:00:45.973919+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.060065269470215}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-25T14:01:16.033655+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059377908706665}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-25T14:01:16.033930+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059377908706665}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-25T14:01:16.034075+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059377908706665}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-25T14:01:16.034282+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059377908706665}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-25T14:01:46.094600+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059906005859375}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-25T14:01:46.094832+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059906005859375}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-25T14:01:46.094947+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059906005859375}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-25T14:01:46.095063+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.059906005859375}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-25T14:02:16.154111+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05872416496277}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-25T14:02:16.154321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05872416496277}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-25T14:02:16.154438+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05872416496277}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-25T14:02:16.154571+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.05872416496277}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-25T14:02:46.218651+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063719511032104}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-25T14:02:46.218932+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063719511032104}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-25T14:02:46.219063+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063719511032104}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-25T14:02:46.219176+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.063719511032104}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-25T14:03:16.284932+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06538438796997}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-25T14:03:16.285159+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06538438796997}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-25T14:03:16.285295+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06538438796997}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-25T14:03:16.285398+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 30.06538438796997}
{"transaction_id": "WARMUP", "timestamp_utc": "2026-01-25T16:15:30.880384+00:00", "prompt": "<warmup prompt>", "raw_output": "{\n  \"transaction_id\": \"WARMUP\",\n  \"llm_adjustment\": 0.0,\n  \"evidence_ids\": [\"E1\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": null\n}\n\n", "model": "llama2", "elapsed_seconds": 30.193673133850098}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-25T16:16:30.951178+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.055511713027954}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-25T16:16:30.951411+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.055511713027954}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-25T16:16:30.951539+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.055511713027954}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-25T16:16:30.951647+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.055511713027954}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-25T16:17:31.011203+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05920052528381}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-25T16:17:31.011429+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05920052528381}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-25T16:17:31.011543+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05920052528381}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-25T16:17:31.011648+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05920052528381}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-25T16:18:31.072965+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.060980558395386}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-25T16:18:31.073262+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.060980558395386}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-25T16:18:31.073393+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.060980558395386}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-25T16:18:31.073514+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.060980558395386}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-25T16:19:31.130701+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05681920051575}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-25T16:19:31.130955+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05681920051575}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-25T16:19:31.131101+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05681920051575}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-25T16:19:31.131211+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05681920051575}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-25T16:20:31.191880+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06034517288208}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-25T16:20:31.192129+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06034517288208}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-25T16:20:31.192250+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06034517288208}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-25T16:20:31.192358+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06034517288208}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-25T16:21:31.251977+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05929517745972}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-25T16:21:31.252220+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05929517745972}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-25T16:21:31.252339+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05929517745972}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-25T16:21:31.252767+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05929517745972}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-25T16:22:31.311546+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05834150314331}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-25T16:22:31.311939+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05834150314331}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-25T16:22:31.312137+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05834150314331}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-25T16:22:31.312258+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05834150314331}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-25T16:23:31.372255+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05964207649231}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-25T16:23:31.372476+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05964207649231}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-25T16:23:31.372608+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05964207649231}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-25T16:23:31.372742+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05964207649231}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-25T16:24:31.430278+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05718684196472}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-25T16:24:31.430498+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05718684196472}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-25T16:24:31.430617+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05718684196472}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-25T16:24:31.430732+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05718684196472}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-25T16:25:31.487061+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05597448348999}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-25T16:25:31.487329+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05597448348999}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-25T16:25:31.487653+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05597448348999}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-25T16:25:31.487885+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05597448348999}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-25T16:26:31.546085+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05775284767151}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-25T16:26:31.546312+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05775284767151}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-25T16:26:31.546457+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05775284767151}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-25T16:26:31.546601+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05775284767151}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-25T16:27:31.609273+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06231069564819}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-25T16:27:31.609626+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06231069564819}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-25T16:27:31.609781+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06231069564819}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-25T16:27:31.609980+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06231069564819}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-25T16:28:31.668786+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05831289291382}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-25T16:28:31.669079+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05831289291382}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-25T16:28:31.669283+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05831289291382}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-25T16:28:31.669426+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05831289291382}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-25T16:29:31.725888+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05610418319702}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-25T16:29:31.726128+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05610418319702}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-25T16:29:31.726253+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05610418319702}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-25T16:29:31.726371+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05610418319702}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-25T16:30:31.786273+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.0595645904541}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-25T16:30:31.786506+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.0595645904541}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-25T16:30:31.786651+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.0595645904541}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-25T16:30:31.786761+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.0595645904541}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-25T16:31:31.845132+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05803990364075}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-25T16:31:31.845347+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05803990364075}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-25T16:31:31.845495+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05803990364075}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-25T16:31:31.845621+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05803990364075}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-25T16:32:31.902977+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057031869888306}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-25T16:32:31.903273+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057031869888306}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-25T16:32:31.903399+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057031869888306}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-25T16:32:31.903504+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057031869888306}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-25T16:33:31.959496+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05567479133606}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-25T16:33:31.959709+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05567479133606}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-25T16:33:31.959850+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05567479133606}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-25T16:33:31.959965+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05567479133606}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-25T16:34:32.019892+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05957770347595}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-25T16:34:32.020128+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05957770347595}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-25T16:34:32.020249+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05957770347595}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-25T16:34:32.020359+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05957770347595}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-25T16:35:32.078483+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05776929855347}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-25T16:35:32.078708+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05776929855347}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-25T16:35:32.078829+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05776929855347}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-25T16:35:32.078945+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05776929855347}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-25T16:36:32.135164+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05585813522339}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-25T16:36:32.135383+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05585813522339}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-25T16:36:32.135501+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05585813522339}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-25T16:36:32.135632+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05585813522339}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-25T16:37:32.197569+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06159687042236}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-25T16:37:32.197803+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06159687042236}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-25T16:37:32.197960+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06159687042236}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-25T16:37:32.198244+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06159687042236}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-25T16:38:32.253060+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05437660217285}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-25T16:38:32.253292+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05437660217285}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-25T16:38:32.253407+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05437660217285}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-25T16:38:32.253523+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05437660217285}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-25T16:39:32.318779+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06493139266968}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-25T16:39:32.319098+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06493139266968}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-25T16:39:32.319232+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06493139266968}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-25T16:39:32.319350+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06493139266968}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-25T16:40:32.380098+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06037092208862}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-25T16:40:32.380347+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06037092208862}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-25T16:40:32.380502+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06037092208862}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-25T16:40:32.380624+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06037092208862}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T10:57:56.374444+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053553104400635}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T10:57:56.375163+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053553104400635}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T10:57:56.384752+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053553104400635}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T10:57:56.384884+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053553104400635}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T10:58:56.444773+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05949950218201}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T10:58:56.445078+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05949950218201}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T10:58:56.445205+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05949950218201}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T10:58:56.445311+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05949950218201}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T10:59:56.499051+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053401947021484}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T10:59:56.499325+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053401947021484}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T10:59:56.499471+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053401947021484}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T10:59:56.499641+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.053401947021484}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T11:00:56.572256+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.072160720825195}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T11:00:56.572506+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.072160720825195}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T11:00:56.572623+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.072160720825195}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T11:00:56.572737+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.072160720825195}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T11:01:56.633622+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06053948402405}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T11:01:56.633856+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06053948402405}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T11:01:56.633998+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06053948402405}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T11:01:56.634118+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06053948402405}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T11:02:56.699453+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06498885154724}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T11:02:56.699725+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06498885154724}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T11:02:56.699971+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06498885154724}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T11:02:56.700113+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06498885154724}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T11:03:56.760587+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06005859375}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T11:03:56.760805+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06005859375}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T11:03:56.760944+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06005859375}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T11:03:56.761283+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06005859375}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T11:04:56.821950+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06022763252258}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T11:04:56.822204+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06022763252258}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T11:04:56.822451+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06022763252258}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T11:04:56.822571+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06022763252258}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T11:05:56.881175+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05827736854553}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T11:05:56.881454+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05827736854553}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T11:05:56.881590+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05827736854553}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T11:05:56.881729+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05827736854553}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T11:06:56.942085+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.059977293014526}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T11:06:56.942312+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.059977293014526}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T11:06:56.942460+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.059977293014526}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T11:06:56.942599+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.059977293014526}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T11:07:57.002060+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05911374092102}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T11:07:57.002321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05911374092102}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T11:07:57.002478+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05911374092102}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T11:07:57.002586+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05911374092102}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T11:08:57.060294+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057368516922}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T11:08:57.060529+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057368516922}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T11:08:57.060650+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057368516922}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T11:08:57.060770+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.057368516922}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T11:09:57.117756+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.056509256362915}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T11:09:57.118004+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.056509256362915}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T11:09:57.118128+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.056509256362915}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T11:09:57.118235+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.056509256362915}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T11:10:57.176692+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.058133125305176}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T11:10:57.176928+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.058133125305176}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T11:10:57.177047+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.058133125305176}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T11:10:57.177261+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.058133125305176}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T11:11:57.237782+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06018090248108}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T11:11:57.238168+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06018090248108}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T11:11:57.238294+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06018090248108}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T11:11:57.238402+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06018090248108}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T11:12:57.297728+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05899715423584}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T11:12:57.298000+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05899715423584}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T11:12:57.298141+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05899715423584}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T11:12:57.298264+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05899715423584}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T11:13:57.375577+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.07697606086731}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T11:13:57.376087+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.07697606086731}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T11:13:57.376499+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.07697606086731}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T11:13:57.376722+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.07697606086731}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T11:14:57.444057+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.066837310791016}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T11:14:57.444321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.066837310791016}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T11:14:57.444443+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.066837310791016}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T11:14:57.444549+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.066837310791016}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T11:15:57.503507+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05862045288086}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T11:15:57.503755+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05862045288086}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T11:15:57.503931+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05862045288086}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T11:15:57.504069+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05862045288086}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T11:16:57.572208+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06779074668884}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T11:16:57.572433+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06779074668884}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T11:16:57.572561+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06779074668884}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T11:16:57.572671+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06779074668884}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T11:17:57.652483+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.079453229904175}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T11:17:57.652757+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.079453229904175}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T11:17:57.653060+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.079453229904175}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T11:17:57.653281+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.079453229904175}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T11:18:57.720936+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067243814468384}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T11:18:57.721205+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067243814468384}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T11:18:57.721349+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067243814468384}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T11:18:57.721490+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067243814468384}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T11:19:57.777927+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05606007575989}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T11:19:57.778203+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05606007575989}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T11:19:57.778321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05606007575989}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T11:19:57.778438+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.05606007575989}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T11:20:57.846554+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067787408828735}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T11:20:57.846813+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067787408828735}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T11:20:57.847033+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067787408828735}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T11:20:57.847231+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.067787408828735}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T11:21:57.915424+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06782293319702}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T11:21:57.915757+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06782293319702}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T11:21:57.915982+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06782293319702}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T11:21:57.916193+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 60.06782293319702}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T12:24:52.354110+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9806766510009766}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T12:24:52.355819+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9806766510009766}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T12:24:52.356000+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9806766510009766}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T12:24:52.362460+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9806766510009766}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T12:24:53.313611+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508001804351807}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T12:24:53.313824+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508001804351807}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T12:24:53.313992+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508001804351807}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T12:24:53.314131+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508001804351807}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T12:24:54.255109+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9406800270080566}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T12:24:54.255362+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9406800270080566}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T12:24:54.255505+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9406800270080566}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T12:24:54.255646+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9406800270080566}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T12:24:55.197522+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9414947032928467}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T12:24:55.197762+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9414947032928467}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T12:24:55.197915+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9414947032928467}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T12:24:55.198068+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9414947032928467}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T12:24:56.136062+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9376270771026611}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T12:24:56.136300+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9376270771026611}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T12:24:56.136466+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9376270771026611}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T12:24:56.136616+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9376270771026611}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T12:24:57.084866+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9479532241821289}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T12:24:57.085083+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9479532241821289}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T12:24:57.085251+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9479532241821289}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T12:24:57.085398+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9479532241821289}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T12:24:58.025327+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396088123321533}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T12:24:58.025518+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396088123321533}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T12:24:58.025640+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396088123321533}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T12:24:58.025776+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396088123321533}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T12:24:58.959782+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9336941242218018}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T12:24:58.959979+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9336941242218018}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T12:24:58.960106+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9336941242218018}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T12:24:58.960259+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9336941242218018}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T12:24:59.900329+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9397854804992676}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T12:24:59.900548+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9397854804992676}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T12:24:59.900705+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9397854804992676}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T12:24:59.900837+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9397854804992676}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T12:25:00.847159+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.946021318435669}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T12:25:00.847406+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.946021318435669}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T12:25:00.847547+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.946021318435669}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T12:25:00.847678+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.946021318435669}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T12:25:01.787653+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396781921386719}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T12:25:01.787854+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396781921386719}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T12:25:01.788000+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396781921386719}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T12:25:01.788119+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9396781921386719}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T12:25:02.744631+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.956190824508667}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T12:25:02.744852+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.956190824508667}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T12:25:02.745002+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.956190824508667}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T12:25:02.745128+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.956190824508667}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T12:25:03.684072+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9386181831359863}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T12:25:03.684296+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9386181831359863}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T12:25:03.684465+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9386181831359863}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T12:25:03.684624+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9386181831359863}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T12:25:04.627979+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9430265426635742}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T12:25:04.628198+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9430265426635742}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T12:25:04.628360+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9430265426635742}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T12:25:04.628491+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9430265426635742}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T12:25:05.573272+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9444546699523926}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T12:25:05.573492+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9444546699523926}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T12:25:05.573643+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9444546699523926}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T12:25:05.573812+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9444546699523926}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T12:25:06.521302+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471938610076904}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T12:25:06.521516+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471938610076904}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T12:25:06.521666+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471938610076904}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T12:25:06.521793+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471938610076904}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T12:25:07.464220+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9421236515045166}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T12:25:07.464469+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9421236515045166}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T12:25:07.464614+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9421236515045166}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T12:25:07.464741+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9421236515045166}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T12:25:08.397996+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9329526424407959}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T12:25:08.398188+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9329526424407959}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T12:25:08.398340+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9329526424407959}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T12:25:08.398481+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9329526424407959}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T12:25:09.346421+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9476399421691895}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T12:25:09.346624+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9476399421691895}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T12:25:09.346752+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9476399421691895}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T12:25:09.346888+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9476399421691895}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T12:25:10.290641+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434518814086914}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T12:25:10.290852+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434518814086914}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T12:25:10.290987+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434518814086914}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T12:25:10.291110+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434518814086914}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T12:25:11.243713+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9522895812988281}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T12:25:11.243915+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9522895812988281}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T12:25:11.244050+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9522895812988281}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T12:25:11.244182+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9522895812988281}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T12:25:12.183745+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392337799072266}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T12:25:12.183946+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392337799072266}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T12:25:12.184094+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392337799072266}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T12:25:12.184251+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392337799072266}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T12:25:13.129252+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.944704532623291}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T12:25:13.129458+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.944704532623291}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T12:25:13.129577+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.944704532623291}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T12:25:13.129710+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.944704532623291}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T12:25:14.083798+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9537713527679443}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T12:25:14.084006+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9537713527679443}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T12:25:14.084140+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9537713527679443}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T12:25:14.084293+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9537713527679443}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T12:25:15.026855+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9422578811645508}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T12:25:15.027064+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9422578811645508}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T12:25:15.027215+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9422578811645508}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T12:25:15.027400+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9422578811645508}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T12:34:01.307391+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.868232250213623}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T12:34:01.307650+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.868232250213623}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T12:34:01.307806+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.868232250213623}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T12:34:01.307957+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.868232250213623}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T12:34:02.258832+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9505832195281982}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T12:34:02.259023+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9505832195281982}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T12:34:02.259167+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9505832195281982}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T12:34:02.259329+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9505832195281982}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T12:34:03.208004+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9483811855316162}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T12:34:03.208198+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9483811855316162}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T12:34:03.208373+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9483811855316162}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T12:34:03.208497+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9483811855316162}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T12:34:04.987986+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.7792093753814697}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T12:34:04.988179+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.7792093753814697}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T12:34:04.988328+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.7792093753814697}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T12:34:04.988465+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 1.7792093753814697}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T12:34:05.932666+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9439027309417725}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T12:34:05.932865+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9439027309417725}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T12:34:05.932983+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9439027309417725}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T12:34:05.933119+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9439027309417725}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T12:34:06.876824+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434075355529785}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T12:34:06.877015+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434075355529785}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T12:34:06.877150+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434075355529785}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T12:34:06.877306+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9434075355529785}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T12:34:07.811446+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9338586330413818}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T12:34:07.811632+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9338586330413818}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T12:34:07.811782+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9338586330413818}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T12:34:07.811912+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9338586330413818}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T12:34:08.755100+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9429304599761963}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T12:34:08.755327+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9429304599761963}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T12:34:08.755469+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9429304599761963}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T12:34:08.755590+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9429304599761963}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T12:34:09.701692+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9458115100860596}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T12:34:09.701882+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9458115100860596}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T12:34:09.702016+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9458115100860596}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T12:34:09.702148+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9458115100860596}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T12:34:10.644076+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9416298866271973}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T12:34:10.644303+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9416298866271973}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T12:34:10.644461+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9416298866271973}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T12:34:10.644583+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9416298866271973}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T12:34:11.609670+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9648032188415527}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T12:34:11.609869+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9648032188415527}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T12:34:11.610004+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9648032188415527}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T12:34:11.610127+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9648032188415527}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T12:34:12.557073+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9466292858123779}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T12:34:12.557282+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9466292858123779}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T12:34:12.557419+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9466292858123779}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T12:34:12.557548+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9466292858123779}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T12:34:13.504365+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9465246200561523}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T12:34:13.504552+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9465246200561523}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T12:34:13.504698+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9465246200561523}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T12:34:13.504821+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9465246200561523}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T12:34:14.437969+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9328629970550537}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T12:34:14.438168+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9328629970550537}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T12:34:14.438329+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9328629970550537}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T12:34:14.438462+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9328629970550537}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T12:34:15.388038+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9492769241333008}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T12:34:15.388251+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9492769241333008}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T12:34:15.388408+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9492769241333008}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T12:34:15.388534+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9492769241333008}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T12:34:16.335302+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9464507102966309}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T12:34:16.335497+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9464507102966309}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T12:34:16.335637+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9464507102966309}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T12:34:16.335768+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9464507102966309}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T12:34:17.295621+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9595859050750732}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T12:34:17.295830+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9595859050750732}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T12:34:17.295960+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9595859050750732}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T12:34:17.296088+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9595859050750732}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T12:34:18.249885+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9535021781921387}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T12:34:18.250077+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9535021781921387}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T12:34:18.250257+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9535021781921387}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T12:34:18.250394+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9535021781921387}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T12:34:19.193964+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9433073997497559}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T12:34:19.194151+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9433073997497559}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T12:34:19.194285+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9433073997497559}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T12:34:19.194411+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9433073997497559}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T12:34:20.133969+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392521381378174}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T12:34:20.134181+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392521381378174}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T12:34:20.134357+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392521381378174}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T12:34:20.134512+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9392521381378174}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T12:34:21.089842+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9549949169158936}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T12:34:21.090029+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9549949169158936}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T12:34:21.090172+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9549949169158936}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T12:34:21.090319+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9549949169158936}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T12:34:22.072554+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9819505214691162}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T12:34:22.072755+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9819505214691162}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T12:34:22.072892+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9819505214691162}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T12:34:22.073015+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9819505214691162}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T12:34:23.038723+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.965388298034668}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T12:34:23.038919+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.965388298034668}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T12:34:23.039060+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.965388298034668}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T12:34:23.039198+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.965388298034668}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T12:34:23.977845+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.938288688659668}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T12:34:23.978044+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.938288688659668}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T12:34:23.978192+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.938288688659668}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T12:34:23.978342+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.938288688659668}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T12:34:24.927533+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9488961696624756}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T12:34:24.927720+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9488961696624756}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T12:34:24.927858+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9488961696624756}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T12:34:24.928001+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9488961696624756}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T12:35:53.637770+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9520065784454346}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T12:35:53.638004+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9520065784454346}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T12:35:53.638141+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9520065784454346}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T12:35:53.638295+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9520065784454346}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T12:35:54.582851+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9442398548126221}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T12:35:54.583046+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9442398548126221}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T12:35:54.583165+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9442398548126221}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T12:35:54.583309+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9442398548126221}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T12:35:55.534404+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508056640625}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T12:35:55.534593+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508056640625}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T12:35:55.534722+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508056640625}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T12:35:55.534834+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508056640625}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T12:35:56.471124+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9360072612762451}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T12:35:56.471346+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9360072612762451}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T12:35:56.471497+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9360072612762451}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T12:35:56.471627+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9360072612762451}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T12:35:57.418166+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9462745189666748}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T12:35:57.418398+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9462745189666748}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T12:35:57.418534+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9462745189666748}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T12:35:57.418655+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9462745189666748}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T12:35:58.375343+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9563989639282227}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T12:35:58.375529+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9563989639282227}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T12:35:58.375651+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9563989639282227}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T12:35:58.375790+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9563989639282227}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T12:35:59.323197+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471042156219482}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T12:35:59.323412+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471042156219482}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T12:35:59.323564+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471042156219482}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T12:35:59.323703+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9471042156219482}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T12:36:00.286249+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9622125625610352}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T12:36:00.286460+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9622125625610352}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T12:36:00.286584+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9622125625610352}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T12:36:00.286717+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9622125625610352}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T12:36:01.258355+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9713292121887207}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T12:36:01.258618+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9713292121887207}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T12:36:01.258779+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9713292121887207}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T12:36:01.259319+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9713292121887207}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T12:36:02.210520+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507110118865967}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T12:36:02.210731+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507110118865967}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T12:36:02.210877+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507110118865967}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T12:36:02.211008+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507110118865967}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T12:36:03.151792+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9404551982879639}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T12:36:03.151986+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9404551982879639}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T12:36:03.152101+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9404551982879639}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T12:36:03.152279+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9404551982879639}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T12:36:04.095311+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9427099227905273}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T12:36:04.095604+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9427099227905273}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T12:36:04.095756+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9427099227905273}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T12:36:04.095883+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9427099227905273}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T12:36:05.036828+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.940619707107544}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T12:36:05.037045+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.940619707107544}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T12:36:05.037195+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.940619707107544}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T12:36:05.037357+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.940619707107544}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T12:36:05.976730+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.939018726348877}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T12:36:05.976985+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.939018726348877}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T12:36:05.977138+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.939018726348877}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T12:36:05.977328+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.939018726348877}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T12:36:06.938764+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9611494541168213}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T12:36:06.938964+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9611494541168213}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T12:36:06.939092+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9611494541168213}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T12:36:06.939247+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9611494541168213}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T12:36:07.875477+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9359545707702637}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T12:36:07.875680+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9359545707702637}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T12:36:07.875817+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9359545707702637}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T12:36:07.875939+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9359545707702637}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T12:36:08.827370+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511408805847168}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T12:36:08.827570+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511408805847168}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T12:36:08.827705+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511408805847168}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T12:36:08.827834+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511408805847168}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T12:36:09.756834+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9287126064300537}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T12:36:09.757038+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9287126064300537}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T12:36:09.757185+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9287126064300537}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T12:36:09.757336+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9287126064300537}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T12:36:10.703135+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9455113410949707}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T12:36:10.703369+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9455113410949707}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T12:36:10.703503+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9455113410949707}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T12:36:10.703624+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9455113410949707}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T12:36:11.642509+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9385881423950195}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T12:36:11.642711+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9385881423950195}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T12:36:11.642850+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9385881423950195}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T12:36:11.642990+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9385881423950195}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T12:36:12.593192+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9499444961547852}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T12:36:12.593415+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9499444961547852}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T12:36:12.593548+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9499444961547852}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T12:36:12.593668+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9499444961547852}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T12:36:13.563649+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9696660041809082}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T12:36:13.563848+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9696660041809082}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T12:36:13.563981+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9696660041809082}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T12:36:13.564112+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9696660041809082}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T12:36:14.513211+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9487960338592529}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T12:36:14.513420+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9487960338592529}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T12:36:14.513567+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9487960338592529}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T12:36:14.513692+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9487960338592529}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T12:36:15.468213+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9542229175567627}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T12:36:15.468435+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9542229175567627}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T12:36:15.468569+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9542229175567627}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T12:36:15.468691+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9542229175567627}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T12:36:16.427300+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9582810401916504}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T12:36:16.427488+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9582810401916504}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T12:36:16.427623+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9582810401916504}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T12:36:16.427769+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9582810401916504}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T12:47:37.586140+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9543192386627197}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T12:47:37.586410+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9543192386627197}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T12:47:37.586570+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9543192386627197}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T12:47:37.586702+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9543192386627197}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T12:47:38.534284+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9472777843475342}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T12:47:38.534499+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9472777843475342}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T12:47:38.534621+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9472777843475342}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T12:47:38.534741+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9472777843475342}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T12:47:39.485860+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508213996887207}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T12:47:39.486050+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508213996887207}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T12:47:39.486192+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508213996887207}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T12:47:39.486370+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9508213996887207}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T12:47:40.437431+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507932662963867}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T12:47:40.437632+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507932662963867}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T12:47:40.437788+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507932662963867}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T12:47:40.437911+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9507932662963867}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T12:47:41.395400+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9572043418884277}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T12:47:41.395637+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9572043418884277}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T12:47:41.395783+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9572043418884277}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T12:47:41.395898+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9572043418884277}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T12:47:42.345217+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9490139484405518}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T12:47:42.345444+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9490139484405518}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T12:47:42.345574+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9490139484405518}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T12:47:42.345713+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9490139484405518}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T12:47:43.294499+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9485042095184326}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T12:47:43.294715+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9485042095184326}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T12:47:43.294855+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9485042095184326}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T12:47:43.294969+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9485042095184326}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T12:47:44.243830+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948519229888916}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T12:47:44.244108+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948519229888916}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T12:47:44.244318+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948519229888916}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T12:47:44.244496+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948519229888916}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T12:47:45.196365+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.951484203338623}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T12:47:45.196572+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.951484203338623}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T12:47:45.196725+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.951484203338623}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T12:47:45.196858+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.951484203338623}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T12:47:46.143217+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9460861682891846}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T12:47:46.143450+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9460861682891846}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T12:47:46.143574+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9460861682891846}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T12:47:46.143712+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9460861682891846}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T12:47:47.096878+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9528863430023193}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T12:47:47.097086+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9528863430023193}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T12:47:47.097213+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9528863430023193}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T12:47:47.097397+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9528863430023193}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T12:47:48.052339+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9546573162078857}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T12:47:48.052555+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9546573162078857}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T12:47:48.052713+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9546573162078857}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T12:47:48.052848+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9546573162078857}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T12:47:49.005570+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9524292945861816}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T12:47:49.005772+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9524292945861816}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T12:47:49.005907+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9524292945861816}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T12:47:49.006028+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9524292945861816}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T12:47:49.942919+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9365777969360352}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T12:47:49.943116+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9365777969360352}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T12:47:49.943286+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9365777969360352}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T12:47:49.943459+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9365777969360352}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T12:47:50.892979+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9491510391235352}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T12:47:50.893187+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9491510391235352}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T12:47:50.893363+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9491510391235352}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T12:47:50.893487+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9491510391235352}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T12:47:51.838431+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9446547031402588}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T12:47:51.838644+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9446547031402588}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T12:47:51.838768+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9446547031402588}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T12:47:51.838880+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9446547031402588}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T12:47:52.787310+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9481513500213623}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T12:47:52.787507+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9481513500213623}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T12:47:52.787627+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9481513500213623}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T12:47:52.787758+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9481513500213623}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T12:47:53.735861+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9477901458740234}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T12:47:53.736115+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9477901458740234}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T12:47:53.736284+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9477901458740234}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T12:47:53.736427+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9477901458740234}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T12:47:54.678632+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9418632984161377}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T12:47:54.678825+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9418632984161377}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T12:47:54.678945+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9418632984161377}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T12:47:54.679072+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9418632984161377}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T12:47:55.630580+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511809349060059}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T12:47:55.630773+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511809349060059}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T12:47:55.630907+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511809349060059}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T12:47:55.631042+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9511809349060059}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T12:47:56.580182+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948822021484375}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T12:47:56.580399+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948822021484375}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T12:47:56.580548+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948822021484375}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T12:47:56.580673+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.948822021484375}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T12:47:57.529587+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9486210346221924}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T12:47:57.529793+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9486210346221924}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T12:47:57.529929+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9486210346221924}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T12:47:57.530052+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9486210346221924}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T12:47:58.485824+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.955446720123291}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T12:47:58.486030+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.955446720123291}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T12:47:58.486173+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.955446720123291}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T12:47:58.486356+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.955446720123291}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T12:47:59.449056+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9623615741729736}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T12:47:59.449331+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9623615741729736}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T12:47:59.449481+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9623615741729736}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T12:47:59.449617+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9623615741729736}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T12:48:00.407426+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9574525356292725}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T12:48:00.407642+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9574525356292725}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T12:48:00.407767+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9574525356292725}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T12:48:00.407900+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2-7b\\'] rc=1 err=\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest  \\x1b[K\\x1b[?25h\\x1b[?2026l\\x1b[?2026h\\x1b[?25l\\x1b[1Gpulling manifest \\x1b[K\\x1b[?25h\\x1b[?2026l\\nError: pull model manifest: file does not exist\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2-7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2-7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2-7b", "elapsed_seconds": 0.9574525356292725}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T15:32:24.926380+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 120.05892491340637}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T15:32:24.927196+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 120.05892491340637}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T15:32:24.927444+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 120.05892491340637}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T15:32:24.927585+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2", "elapsed_seconds": 120.05892491340637}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-26T15:38:15.239436+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05746579170227}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-26T15:38:15.249397+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05746579170227}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-26T15:38:15.249638+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05746579170227}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-26T15:38:15.249751+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05746579170227}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-26T15:40:15.314356+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06381368637085}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-26T15:40:15.314600+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06381368637085}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-26T15:40:15.314722+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06381368637085}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-26T15:40:15.314845+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06381368637085}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-26T15:42:15.373907+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05869817733765}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-26T15:42:15.374226+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05869817733765}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-26T15:42:15.374354+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05869817733765}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-26T15:42:15.374461+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05869817733765}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-26T15:44:15.445721+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0709137916565}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-26T15:44:15.446146+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0709137916565}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-26T15:44:15.446294+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0709137916565}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-26T15:44:15.446399+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0709137916565}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-26T15:46:15.522187+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07545137405396}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-26T15:46:15.522446+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07545137405396}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-26T15:46:15.522561+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07545137405396}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-26T15:46:15.522664+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07545137405396}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-26T15:48:15.593321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07031345367432}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-26T15:48:15.593608+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07031345367432}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-26T15:48:15.593735+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07031345367432}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-26T15:48:15.593859+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07031345367432}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-26T15:50:15.663321+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06909084320068}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-26T15:50:15.663737+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06909084320068}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-26T15:50:15.663938+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06909084320068}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-26T15:50:15.664104+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06909084320068}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-26T15:52:15.718447+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05399227142334}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-26T15:52:15.718635+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05399227142334}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-26T15:52:15.718755+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05399227142334}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-26T15:52:15.718861+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05399227142334}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-26T15:54:15.774317+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05517840385437}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-26T15:54:15.774618+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05517840385437}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-26T15:54:15.774783+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05517840385437}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-26T15:54:15.774952+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05517840385437}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-26T15:56:15.836782+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06146192550659}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-26T15:56:15.837039+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06146192550659}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-26T15:56:15.837179+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06146192550659}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-26T15:56:15.837314+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06146192550659}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-26T15:58:15.900854+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06321597099304}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-26T15:58:15.901059+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06321597099304}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-26T15:58:15.901206+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06321597099304}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-26T15:58:15.901324+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06321597099304}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-26T16:00:15.959513+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05787348747253}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-26T16:00:15.959767+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05787348747253}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-26T16:00:15.959901+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05787348747253}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-26T16:00:15.960005+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05787348747253}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-26T16:02:16.027349+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06688213348389}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-26T16:02:16.027690+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06688213348389}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-26T16:02:16.027808+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06688213348389}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-26T16:02:16.027905+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06688213348389}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-26T16:04:16.095342+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06708407402039}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-26T16:04:16.095616+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06708407402039}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-26T16:04:16.095769+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06708407402039}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-26T16:04:16.095890+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06708407402039}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-26T16:06:16.154889+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05856657028198}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-26T16:06:16.155111+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05856657028198}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-26T16:06:16.155250+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05856657028198}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-26T16:06:16.155380+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05856657028198}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-26T16:08:16.212530+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05677604675293}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-26T16:08:16.212783+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05677604675293}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-26T16:08:16.212903+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05677604675293}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-26T16:08:16.213257+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05677604675293}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-26T16:10:16.280275+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0666229724884}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-26T16:10:16.280566+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0666229724884}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-26T16:10:16.280695+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0666229724884}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-26T16:10:16.280813+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.0666229724884}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-26T16:12:16.346851+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06564736366272}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-26T16:12:16.347137+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06564736366272}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-26T16:12:16.347262+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06564736366272}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-26T16:12:16.347401+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06564736366272}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-26T16:14:16.421261+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07351112365723}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-26T16:14:16.421514+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07351112365723}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-26T16:14:16.421639+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07351112365723}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-26T16:14:16.421760+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07351112365723}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-26T16:16:16.486785+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06467485427856}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-26T16:16:16.487031+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06467485427856}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-26T16:16:16.487194+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06467485427856}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-26T16:16:16.487313+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06467485427856}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-26T16:18:16.546014+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05838203430176}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-26T16:18:16.546351+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05838203430176}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-26T16:18:16.546474+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05838203430176}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-26T16:18:16.546594+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05838203430176}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-26T16:20:16.600182+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05325603485107}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-26T16:20:16.600490+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05325603485107}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-26T16:20:16.600606+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05325603485107}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-26T16:20:16.600875+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.05325603485107}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-26T16:22:16.674467+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07324552536011}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-26T16:22:16.674724+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07324552536011}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-26T16:22:16.674854+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07324552536011}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-26T16:22:16.674959+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.07324552536011}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-26T16:24:16.740154+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06481385231018}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-26T16:24:16.740411+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06481385231018}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-26T16:24:16.740541+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06481385231018}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-26T16:24:16.740662+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06481385231018}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-26T16:26:16.803044+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06204271316528}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-26T16:26:16.803636+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06204271316528}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-26T16:26:16.803960+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06204271316528}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-26T16:26:16.804231+00:00", "prompt": "<batched prompt; batch_size=4>", "raw_output": "__OLLAMA_ERROR__ RuntimeError('ollama run/generate/chat attempts failed. Details:\\ncmd=[\\'ollama\\', \\'run\\', \\'llama2:7b\\'] rc=timeout err=command timed out\\ncmd=[\\'ollama\\', \\'generate\\', \\'llama2:7b\\', \\'--temperature\\', \\'0\\'] rc=1 err=Error: unknown command \"generate\" for \"ollama\"\\ncmd=[\\'ollama\\', \\'chat\\', \\'llama2:7b\\', \\'--no-stream\\'] rc=1 err=Error: unknown command \"chat\" for \"ollama\"')", "model": "llama2:7b", "elapsed_seconds": 120.06204271316528}
{"transaction_id": "T100000", "timestamp_utc": "2026-01-27T17:22:07.481779+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100000\",\n  \"baseline_score\": 0.005170141998678446,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100000\",\n  \"baseline_score\": 0.005170141998678446,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.313179016113281}
{"transaction_id": "T100001", "timestamp_utc": "2026-01-27T17:22:15.806895+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100001\",\n  \"baseline_score\": 0.005170081835240125,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100001\",\n  \"baseline_score\": 0.005170081835240125,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"explanation\": \"\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.322506427764893}
{"transaction_id": "T100002", "timestamp_utc": "2026-01-27T17:22:29.650439+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100002\",\n  \"baseline_score\": 0.005169880017638207,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100002\",\n  \"baseline_score\": 0.005169880017638207,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"The merchant was high-risk, and the recent device mismatch explains this.\",\n  \"confidence\": 0.8,\n  \"llm_adjustment\": 5.169880017638207,\n  \"evidence_ids\": [\"E1\",\"E2\",\"E3\"]\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 13.843194961547852}
{"transaction_id": "T100003", "timestamp_utc": "2026-01-27T17:22:37.777145+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100003\",\n  \"baseline_score\": 0.005169960763305425,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100003\",\n  \"baseline_score\": 0.005169960763305425,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.126363277435303}
{"transaction_id": "T100004", "timestamp_utc": "2026-01-27T17:22:48.299671+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100004\",\n  \"baseline_score\": 0.00517012532800436,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100004\",\n  \"baseline_score\": 0.00517012532800436,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.522159337997437}
{"transaction_id": "T100005", "timestamp_utc": "2026-01-27T17:22:58.763319+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100005\",\n  \"baseline_score\": 0.0051701064221560955,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100005\",\n  \"baseline_score\": 0.0051701064221560955,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.463307857513428}
{"transaction_id": "T100006", "timestamp_utc": "2026-01-27T17:23:08.055735+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100006\",\n  \"baseline_score\": 0.005170174781233073,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100006\",\n  \"baseline_score\": 0.005170174781233073,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.292059659957886}
{"transaction_id": "T100007", "timestamp_utc": "2026-01-27T17:23:14.211855+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100007\",\n  \"baseline_score\": 0.00517014330253005,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100007\",\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.1557698249816895}
{"transaction_id": "T100008", "timestamp_utc": "2026-01-27T17:23:22.232341+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100008\",\n  \"baseline_score\": 0.00516997454687953,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100008\",\n  \"baseline_score\": 0.00516997454687953,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.020117282867432}
{"transaction_id": "T100009", "timestamp_utc": "2026-01-27T17:23:31.922209+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100009\",\n  \"baseline_score\": 0.005170130077749491,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100009\",\n  \"baseline_score\": 0.005170130077749491,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.689509153366089}
{"transaction_id": "T100010", "timestamp_utc": "2026-01-27T17:23:42.453426+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100010\",\n  \"baseline_score\": 0.005170019064098597,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100010\",\n  \"baseline_score\": 0.005170019064098597,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.530829429626465}
{"transaction_id": "T100011", "timestamp_utc": "2026-01-27T17:23:48.482747+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100011\",\n  \"baseline_score\": 0.00517010260373354,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100011\",\n  \"llm_adjustment\": 5,\n  \"evidence_ids\": [\"E1\",\"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.028960227966309}
{"transaction_id": "T100012", "timestamp_utc": "2026-01-27T17:23:59.020689+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100012\",\n  \"baseline_score\": 0.005170077458024025,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100012\",\n  \"baseline_score\": 0.005170077458024025,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.537628412246704}
{"transaction_id": "T100013", "timestamp_utc": "2026-01-27T17:24:08.848412+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100013\",\n  \"baseline_score\": 0.0051701109856367115,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100013\",\n  \"baseline_score\": 0.0051701109856367115,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.827381134033203}
{"transaction_id": "T100014", "timestamp_utc": "2026-01-27T17:24:19.313855+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100014\",\n  \"baseline_score\": 0.005170084349811077,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100014\",\n  \"baseline_score\": 0.005170084349811077,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.465123653411865}
{"transaction_id": "T100015", "timestamp_utc": "2026-01-27T17:24:28.045659+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100015\",\n  \"baseline_score\": 0.005170052964240312,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100015\",\n  \"baseline_score\": 0.005170052964240312,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.731482744216919}
{"transaction_id": "T100016", "timestamp_utc": "2026-01-27T17:24:38.584478+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100016\",\n  \"baseline_score\": 0.005169950146228075,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100016\",\n  \"baseline_score\": 0.005169950146228075,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.538453340530396}
{"transaction_id": "T100017", "timestamp_utc": "2026-01-27T17:24:48.814470+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100017\",\n  \"baseline_score\": 0.005169984605163336,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100017\",\n  \"baseline_score\": 0.005169984605163336,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.229649066925049}
{"transaction_id": "T100018", "timestamp_utc": "2026-01-27T17:24:59.500579+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100018\",\n  \"baseline_score\": 0.005169981811195612,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100018\",\n  \"baseline_score\": 0.005169981811195612,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"}\n  ],\n  \"explanation\": \"\",\n  \"confidence\": null,\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\",\"E2\"],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.68579888343811}
{"transaction_id": "T100019", "timestamp_utc": "2026-01-27T17:25:05.693789+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100019\",\n  \"baseline_score\": 0.005170007515698671,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100019\",\n  \"llm_adjustment\": 0.0001,\n  \"evidence_ids\": [\"E1\",\"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.192840337753296}
{"transaction_id": "T100020", "timestamp_utc": "2026-01-27T17:25:16.450821+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100020\",\n  \"baseline_score\": 0.00517009012401104,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100020\",\n  \"baseline_score\": 0.00517009012401104,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"\",\n  \"confidence\": null\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.756659746170044}
{"transaction_id": "T100021", "timestamp_utc": "2026-01-27T17:25:27.274151+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100021\",\n  \"baseline_score\": 0.0051700791344046594,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100021\",\n  \"baseline_score\": 0.0051700791344046594,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.823004961013794}
{"transaction_id": "T100022", "timestamp_utc": "2026-01-27T17:25:36.606282+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100022\",\n  \"baseline_score\": 0.005169932823628187,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100022\",\n  \"baseline_score\": 0.005169932823628187,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.33175539970398}
{"transaction_id": "T100023", "timestamp_utc": "2026-01-27T17:25:43.261241+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100023\",\n  \"baseline_score\": 0.005169999413192272,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100023\",\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000, merchant_risk=?, recent_device_mismatch\",\n  \"confidence\": 1\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.654592275619507}
{"transaction_id": "T100024", "timestamp_utc": "2026-01-27T17:25:51.914597+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100024\",\n  \"baseline_score\": 0.005169944372028112,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100024\",\n  \"baseline_score\": 0.005169944372028112,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"explanation\": \"No evidence available for E1\",\n  \"confidence\": 1\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.65300989151001}
{"transaction_id": "T100025", "timestamp_utc": "2026-01-27T17:26:01.547362+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100025\",\n  \"baseline_score\": 0.00516997454687953,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100025\",\n  \"baseline_score\": 0.00516997454687953,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"}\n  ],\n  \"explanation\": \"\",\n  \"confidence\": 0,\n  \"llm_adjustment\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.632413625717163}
{"transaction_id": "T100026", "timestamp_utc": "2026-01-27T17:26:12.206969+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100026\",\n  \"baseline_score\": 0.0051700914278626445,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100026\",\n  \"baseline_score\": 0.0051700914278626445,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.659255981445312}
{"transaction_id": "T100027", "timestamp_utc": "2026-01-27T17:26:18.554289+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100027\",\n  \"baseline_score\": 0.005169940926134586,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\"transaction_id\":\"T100027\",\"baseline_score\":0.005169940926134586,\"features\":{\"model_version\":\"xgb_v1\"},\"top_k_evidence\":[{\"id\":\"E1\"},{\"id\":\"E2\"},{\"id\":\"E3\"}],\"max_delta\":0.05}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.346993923187256}
{"transaction_id": "T100028", "timestamp_utc": "2026-01-27T17:26:28.333265+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100028\",\n  \"baseline_score\": 0.005169997829943896,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100028\",\n  \"baseline_score\": 0.005169997829943896,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.778608798980713}
{"transaction_id": "T100029", "timestamp_utc": "2026-01-27T17:26:38.841619+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100029\",\n  \"baseline_score\": 0.005170110054314137,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100029\",\n  \"baseline_score\": 0.005170110054314137,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.508001327514648}
{"transaction_id": "T100030", "timestamp_utc": "2026-01-27T17:26:45.438902+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100030\",\n  \"baseline_score\": 0.005170056317001581,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100030\",\n  \"llm_adjustment\": 1.0000,\n  \"evidence_ids\": [\n    \"E2\",\n    \"E3\"\n  ],\n  \"explanation\": \"merchant_risk=?\",\n  \"confidence\": 0.4\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.596965312957764}
{"transaction_id": "T100031", "timestamp_utc": "2026-01-27T17:26:55.008192+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100031\",\n  \"baseline_score\": 0.005170101393014192,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100031\",\n  \"baseline_score\": 0.005170101393014192,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.568967342376709}
{"transaction_id": "T100032", "timestamp_utc": "2026-01-27T17:27:04.685704+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100032\",\n  \"baseline_score\": 0.0051701322197914125,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100032\",\n  \"baseline_score\": 0.0051701322197914125,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.67715048789978}
{"transaction_id": "T100033", "timestamp_utc": "2026-01-27T17:27:14.261949+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100033\",\n  \"baseline_score\": 0.005169986654073,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100033\",\n  \"baseline_score\": 0.005169986654073,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.575916051864624}
{"transaction_id": "T100034", "timestamp_utc": "2026-01-27T17:27:23.718637+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100034\",\n  \"baseline_score\": 0.005170093383640051,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100034\",\n  \"baseline_score\": 0.005170093383640051,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.456344842910767}
{"transaction_id": "T100035", "timestamp_utc": "2026-01-27T17:27:33.573688+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100035\",\n  \"baseline_score\": 0.0051700565032660965,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100035\",\n  \"baseline_score\": 0.0051700565032660965,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.854711771011353}
{"transaction_id": "T100036", "timestamp_utc": "2026-01-27T17:27:40.008894+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100036\",\n  \"baseline_score\": 0.0051700822077691555,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100036\",\n  \"llm_adjustment\": 0.025,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0.7\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.434819936752319}
{"transaction_id": "T100037", "timestamp_utc": "2026-01-27T17:27:49.513095+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100037\",\n  \"baseline_score\": 0.00517015578225255,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100037\",\n  \"baseline_score\": 0.00517015578225255,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05,\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.503870487213135}
{"transaction_id": "T100038", "timestamp_utc": "2026-01-27T17:27:58.443265+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100038\",\n  \"baseline_score\": 0.00517003508284688,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100038\",\n  \"baseline_score\": 0.00517003508284688,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.929835796356201}
{"transaction_id": "T100039", "timestamp_utc": "2026-01-27T17:28:09.119923+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100039\",\n  \"baseline_score\": 0.005170009098947048,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100039\",\n  \"baseline_score\": 0.005170009098947048,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.676296472549438}
{"transaction_id": "T100040", "timestamp_utc": "2026-01-27T17:28:16.905533+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100040\",\n  \"baseline_score\": 0.005169970821589232,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100040\",\n  \"baseline_score\": 0.005169970821589232,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.785277366638184}
{"transaction_id": "T100041", "timestamp_utc": "2026-01-27T17:28:28.910647+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100041\",\n  \"baseline_score\": 0.005170167423784733,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100041\",\n  \"baseline_score\": 0.005170167423784733,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"This is a concise factual explanation based only on the provided top_k_evidence and features.\",\n  \"confidence\": 0.5\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 12.004728317260742}
{"transaction_id": "T100042", "timestamp_utc": "2026-01-27T17:28:41.884085+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100042\",\n  \"baseline_score\": 0.005170052126049996,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100042\",\n  \"baseline_score\": 0.005170052126049996,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000 merchant_risk=? recent_device_mismatch\",\n  \"confidence\": null\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 12.973097562789917}
{"transaction_id": "T100043", "timestamp_utc": "2026-01-27T17:28:48.163820+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100043\",\n  \"baseline_score\": 0.005170038063079118,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100043\",\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.27942967414856}
{"transaction_id": "T100044", "timestamp_utc": "2026-01-27T17:29:00.073211+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100044\",\n  \"baseline_score\": 0.005170057713985443,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100044\",\n  \"baseline_score\": 0.005170057713985443,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05,\n  \"explanation\": \" baseline=0.0000, merchant_risk=?, recent_device_mismatch.\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 11.909051179885864}
{"transaction_id": "T100045", "timestamp_utc": "2026-01-27T17:29:06.285320+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100045\",\n  \"baseline_score\": 0.005170100741088391,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100045\",\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\",\"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0.5\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.211758375167847}
{"transaction_id": "T100046", "timestamp_utc": "2026-01-27T17:29:16.926804+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100046\",\n  \"baseline_score\": 0.005170023906975985,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100046\",\n  \"baseline_score\": 0.005170023906975985,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.641119241714478}
{"transaction_id": "T100047", "timestamp_utc": "2026-01-27T17:29:27.763691+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100047\",\n  \"baseline_score\": 0.005170076992362738,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100047\",\n  \"baseline_score\": 0.005170076992362738,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"explanation\": \"\",\n  \"confidence\": null,\n  \"llm_adjustment\": 0.04\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.836543083190918}
{"transaction_id": "T100048", "timestamp_utc": "2026-01-27T17:29:37.803392+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100048\",\n  \"baseline_score\": 0.005169856082648039,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100048\",\n  \"baseline_score\": 0.005169856082648039,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.039300680160522}
{"transaction_id": "T100049", "timestamp_utc": "2026-01-27T17:29:46.796405+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100049\",\n  \"baseline_score\": 0.0051700262352824215,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100049\",\n  \"baseline_score\": 0.0051700262352824215,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.9925856590271}
{"transaction_id": "T100050", "timestamp_utc": "2026-01-27T17:29:57.406127+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100050\",\n  \"baseline_score\": 0.00517002260312438,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100050\",\n  \"baseline_score\": 0.00517002260312438,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.609380722045898}
{"transaction_id": "T100051", "timestamp_utc": "2026-01-27T17:30:07.964227+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100051\",\n  \"baseline_score\": 0.005170117784291506,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100051\",\n  \"baseline_score\": 0.005170117784291506,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.557764768600464}
{"transaction_id": "T100052", "timestamp_utc": "2026-01-27T17:30:14.302796+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100052\",\n  \"baseline_score\": 0.0051700277253985405,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100052\",\n  \"llm_adjustment\": 0.00,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0.00\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.338203191757202}
{"transaction_id": "T100053", "timestamp_utc": "2026-01-27T17:30:24.798600+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100053\",\n  \"baseline_score\": 0.005170112010091543,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100053\",\n  \"baseline_score\": 0.005170112010091543,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.49546217918396}
{"transaction_id": "T100054", "timestamp_utc": "2026-01-27T17:30:35.492651+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100054\",\n  \"baseline_score\": 0.005170080438256263,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100054\",\n  \"baseline_score\": 0.005170080438256263,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.693716764450073}
{"transaction_id": "T100055", "timestamp_utc": "2026-01-27T17:30:42.488702+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100055\",\n  \"baseline_score\": 0.005170031543821096,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100055\",\n  \"llm_adjustment\": 0.04,\n  \"evidence_ids\": [\n    \"E1\",\n    \"E2\"\n  ],\n  \"explanation\": \"baseline=0.0000 merchant_risk=? recent_device_mismatch\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.995750665664673}
{"transaction_id": "T100056", "timestamp_utc": "2026-01-27T17:30:50.659286+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100056\",\n  \"baseline_score\": 0.005170083232223987,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100056\",\n  \"baseline_score\": 0.005170083232223987,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"explanation\": \"\",\n  \"confidence\": null\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.170249462127686}
{"transaction_id": "T100057", "timestamp_utc": "2026-01-27T17:30:57.332591+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100057\",\n  \"baseline_score\": 0.005169980134814978,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100057\",\n  \"llm_adjustment\": 0.00,\n  \"evidence_ids\": [\"E1\",\"E2\"],\n  \"explanation\": \"baseline=0.0000 merchant_risk=? recent device mismatch\",\n  \"confidence\": 0.75\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.672906160354614}
{"transaction_id": "T100058", "timestamp_utc": "2026-01-27T17:31:07.676207+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100058\",\n  \"baseline_score\": 0.0051699717529118065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100058\",\n  \"baseline_score\": 0.0051699717529118065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.343297958374023}
{"transaction_id": "T100059", "timestamp_utc": "2026-01-27T17:31:16.388507+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100059\",\n  \"baseline_score\": 0.005170124676078558,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100059\",\n  \"baseline_score\": 0.005170124676078558,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.7119619846344}
{"transaction_id": "T100060", "timestamp_utc": "2026-01-27T17:31:24.435017+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100060\",\n  \"baseline_score\": 0.0051700852811336516,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100060\",\n  \"baseline_score\": 0.0051700852811336516,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    }\n  ],\n  \"explanation\": \"\",\n  \"confidence\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.04620361328125}
{"transaction_id": "T100061", "timestamp_utc": "2026-01-27T17:31:35.005696+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100061\",\n  \"baseline_score\": 0.005170112382620573,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100061\",\n  \"baseline_score\": 0.005170112382620573,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.57030463218689}
{"transaction_id": "T100062", "timestamp_utc": "2026-01-27T17:31:45.549088+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100062\",\n  \"baseline_score\": 0.005170116480439901,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100062\",\n  \"baseline_score\": 0.005170116480439901,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.5430748462677}
{"transaction_id": "T100063", "timestamp_utc": "2026-01-27T17:31:55.114933+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100063\",\n  \"baseline_score\": 0.005170018132776022,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100063\",\n  \"baseline_score\": 0.005170018132776022,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.565526723861694}
{"transaction_id": "T100064", "timestamp_utc": "2026-01-27T17:32:05.716591+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100064\",\n  \"baseline_score\": 0.0051699717529118065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100064\",\n  \"baseline_score\": 0.0051699717529118065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.601348638534546}
{"transaction_id": "T100065", "timestamp_utc": "2026-01-27T17:32:16.179438+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100065\",\n  \"baseline_score\": 0.00516992686316371,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100065\",\n  \"baseline_score\": 0.00516992686316371,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.462485313415527}
{"transaction_id": "T100066", "timestamp_utc": "2026-01-27T17:32:22.870482+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100066\",\n  \"baseline_score\": 0.005170081928372383,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100066\",\n  \"llm_adjustment\": 0.0005,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000 merchant_risk=? recent device mismatch\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.690730571746826}
{"transaction_id": "T100067", "timestamp_utc": "2026-01-27T17:32:32.520602+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100067\",\n  \"baseline_score\": 0.005170047283172607,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100067\",\n  \"baseline_score\": 0.005170047283172607,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.649786949157715}
{"transaction_id": "T100068", "timestamp_utc": "2026-01-27T17:32:43.834888+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100068\",\n  \"baseline_score\": 0.005170115176588297,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100068\",\n  \"baseline_score\": 0.005170115176588297,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05,\n  \"llm_adjustment\": 0.000001\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 11.31396198272705}
{"transaction_id": "T100069", "timestamp_utc": "2026-01-27T17:32:53.600542+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100069\",\n  \"baseline_score\": 0.0051701169461011885,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100069\",\n  \"baseline_score\": 0.0051701169461011885,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.765318155288696}
{"transaction_id": "T100070", "timestamp_utc": "2026-01-27T17:33:03.366009+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100070\",\n  \"baseline_score\": 0.005170106049627065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100070\",\n  \"baseline_score\": 0.005170106049627065,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.765131950378418}
{"transaction_id": "T100071", "timestamp_utc": "2026-01-27T17:33:13.075194+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100071\",\n  \"baseline_score\": 0.00517011471092701,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100071\",\n  \"baseline_score\": 0.00517011471092701,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.708845376968384}
{"transaction_id": "T100072", "timestamp_utc": "2026-01-27T17:33:21.102896+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100072\",\n  \"baseline_score\": 0.005169999413192272,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100072\",\n  \"baseline_score\": 0.005169999413192272,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.027347564697266}
{"transaction_id": "T100073", "timestamp_utc": "2026-01-27T17:33:31.093380+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100073\",\n  \"baseline_score\": 0.005169956758618355,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100073\",\n  \"baseline_score\": 0.005169956758618355,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ]\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.99011516571045}
{"transaction_id": "T100074", "timestamp_utc": "2026-01-27T17:33:40.823925+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100074\",\n  \"baseline_score\": 0.005170026794075966,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100074\",\n  \"baseline_score\": 0.005170026794075966,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.730193853378296}
{"transaction_id": "T100075", "timestamp_utc": "2026-01-27T17:33:47.270204+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100075\",\n  \"baseline_score\": 0.00517000425606966,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100075\",\n  \"llm_adjustment\": 0.0001,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0.9999\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.445951700210571}
{"transaction_id": "T100076", "timestamp_utc": "2026-01-27T17:33:56.777037+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100076\",\n  \"baseline_score\": 0.005170027446001768,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100076\",\n  \"baseline_score\": 0.005170027446001768,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.506471872329712}
{"transaction_id": "T100077", "timestamp_utc": "2026-01-27T17:34:07.337208+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100077\",\n  \"baseline_score\": 0.0051701215095818044,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100077\",\n  \"baseline_score\": 0.0051701215095818044,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.55981183052063}
{"transaction_id": "T100078", "timestamp_utc": "2026-01-27T17:34:17.741058+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100078\",\n  \"baseline_score\": 0.005170019622892141,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100078\",\n  \"baseline_score\": 0.005170019622892141,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.403491497039795}
{"transaction_id": "T100079", "timestamp_utc": "2026-01-27T17:34:28.269312+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100079\",\n  \"baseline_score\": 0.005170119553804397,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100079\",\n  \"baseline_score\": 0.005170119553804397,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.527932167053223}
{"transaction_id": "T100080", "timestamp_utc": "2026-01-27T17:34:38.596352+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100080\",\n  \"baseline_score\": 0.005169988796114922,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100080\",\n  \"baseline_score\": 0.005169988796114922,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.326675176620483}
{"transaction_id": "T100081", "timestamp_utc": "2026-01-27T17:34:48.566771+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100081\",\n  \"baseline_score\": 0.005170044861733914,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100081\",\n  \"baseline_score\": 0.005170044861733914,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"},\n    {\"id\": \"E3\", \"text\": \"recent device mismatch\"}\n  ],\n  \"max_delta\": 0.05,\n  \"explanation\": \"\"\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.970067739486694}
{"transaction_id": "T100082", "timestamp_utc": "2026-01-27T17:34:58.342062+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100082\",\n  \"baseline_score\": 0.005169965326786041,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100082\",\n  \"baseline_score\": 0.005169965326786041,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"},\n    {\"id\": \"E3\", \"text\": \"recent_device_mismatch\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.774962186813354}
{"transaction_id": "T100083", "timestamp_utc": "2026-01-27T17:35:08.844518+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100083\",\n  \"baseline_score\": 0.005170103721320629,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100083\",\n  \"baseline_score\": 0.005170103721320629,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.50189995765686}
{"transaction_id": "T100084", "timestamp_utc": "2026-01-27T17:35:16.819554+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100084\",\n  \"baseline_score\": 0.005170040111988783,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100084\",\n  \"baseline_score\": 0.005170040111988783,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.9746644496917725}
{"transaction_id": "T100085", "timestamp_utc": "2026-01-27T17:35:26.725004+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100085\",\n  \"baseline_score\": 0.005169975478202105,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100085\",\n  \"baseline_score\": 0.005169975478202105,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ]\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 9.905090570449829}
{"transaction_id": "T100086", "timestamp_utc": "2026-01-27T17:35:37.249331+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100086\",\n  \"baseline_score\": 0.005170121043920517,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100086\",\n  \"baseline_score\": 0.005170121043920517,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.523932218551636}
{"transaction_id": "T100087", "timestamp_utc": "2026-01-27T17:35:43.326359+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100087\",\n  \"baseline_score\": 0.005170100927352905,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100087\",\n  \"llm_adjustment\": 0,\n  \"evidence_ids\": [\"E1\", \"E2\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.076671361923218}
{"transaction_id": "T100088", "timestamp_utc": "2026-01-27T17:35:51.971872+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100088\",\n  \"baseline_score\": 0.005170166399329901,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100088\",\n  \"baseline_score\": 0.005170166399329901,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.645148754119873}
{"transaction_id": "T100089", "timestamp_utc": "2026-01-27T17:36:02.462619+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100089\",\n  \"baseline_score\": 0.005170182790607214,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100089\",\n  \"baseline_score\": 0.005170182790607214,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.490378141403198}
{"transaction_id": "T100090", "timestamp_utc": "2026-01-27T17:36:10.411733+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100090\",\n  \"baseline_score\": 0.0051700672134757045,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100090\",\n  \"baseline_score\": 0.0051700672134757045,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.948801279067993}
{"transaction_id": "T100091", "timestamp_utc": "2026-01-27T17:36:20.879543+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100091\",\n  \"baseline_score\": 0.005170063860714435,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100091\",\n  \"baseline_score\": 0.005170063860714435,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.467477321624756}
{"transaction_id": "T100092", "timestamp_utc": "2026-01-27T17:36:31.313492+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100092\",\n  \"baseline_score\": 0.005169982090592384,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100092\",\n  \"baseline_score\": 0.005169982090592384,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.433614253997803}
{"transaction_id": "T100093", "timestamp_utc": "2026-01-27T17:36:42.521297+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100093\",\n  \"baseline_score\": 0.005170023441314698,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100093\",\n  \"baseline_score\": 0.005170023441314698,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05,\n  \"explanation\": \"\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 11.20746660232544}
{"transaction_id": "T100094", "timestamp_utc": "2026-01-27T17:36:52.939926+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100094\",\n  \"baseline_score\": 0.005170061532407999,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100094\",\n  \"baseline_score\": 0.005170061532407999,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 10.418278455734253}
{"transaction_id": "T100095", "timestamp_utc": "2026-01-27T17:36:59.257133+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100095\",\n  \"baseline_score\": 0.005170034803450107,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100095\",\n  \"llm_adjustment\": 0.01,\n  \"evidence_ids\": [\"E1\", \"E3\"],\n  \"explanation\": \"baseline=0.0000\",\n  \"confidence\": 1.0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.316882848739624}
{"transaction_id": "T100096", "timestamp_utc": "2026-01-27T17:37:07.079308+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100096\",\n  \"baseline_score\": 0.005170010961592197,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100096\",\n  \"baseline_score\": 0.005170010961592197,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.821829319000244}
{"transaction_id": "T100097", "timestamp_utc": "2026-01-27T17:37:14.178200+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100097\",\n  \"baseline_score\": 0.005170118715614081,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100097\",\n  \"llm_adjustment\": 0.0025,\n  \"evidence_ids\": [\"E1\", \"E3\"],\n  \"explanation\": \"baseline=0.0000, merchant_risk=?, recent_device_mismatch=0.1\",\n  \"confidence\": 0\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 7.098524808883667}
{"transaction_id": "T100098", "timestamp_utc": "2026-01-27T17:37:22.797104+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100098\",\n  \"baseline_score\": 0.005169999226927758,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\n  \"transaction_id\": \"T100098\",\n  \"baseline_score\": 0.005169999226927758,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\"id\": \"E1\", \"text\": \"baseline=0.0000\"},\n    {\"id\": \"E2\", \"text\": \"merchant_risk=?\"}\n  ],\n  \"max_delta\": 0.05\n}\n\n", "model": "llama3.2:1b", "elapsed_seconds": 8.618546962738037}
{"transaction_id": "T100099", "timestamp_utc": "2026-01-27T17:37:29.185938+00:00", "prompt": "\nYou are a strict fraud-triage assistant. RETURN EXACTLY valid JSON and NOTHING ELSE.\nDo NOT output any prose, commentary, markup, or extra tokens outside the JSON. The JSON must match\nthe schema and types exactly.\n\nWhen Input contains a single transaction, return exactly a single JSON object matching the schema.\nWhen Input contains a transactions array (batched mode), return exactly a JSON array with one JSON\nobject per input transaction in the same order. Do NOT include extra text or commentary.\n\nSchema (must match exactly for each object):\n{\n  \"transaction_id\": \"<string>\",\n  \"llm_adjustment\": <number>,       // additive delta to baseline_score (numeric)\n  \"evidence_ids\": [\"E1\",\"E2\"],     // list of evidence IDs (must be subset of provided top_k_evidence ids)\n  \"explanation\": \"<string>\",        // concise factual explanation based ONLY on the provided top_k_evidence and features (<=250 chars)\n  \"confidence\": <number>            // optional (0.0 .. 1.0)\n}\n\nStrict rules:\n- Return EXACTLY the required JSON (single object or array). No surrounding text, no code fences.\n- evidence_ids MUST reference the ids exactly as provided in the top_k_evidence list for that transaction.\n- llm_adjustment must be numeric. The caller will clamp to +/- {max_delta:.4f}.\n- Keep explanation factual and based only on the provided top_k_evidence and features.\n- Temperature must be 0 (deterministic). Be concise.\n- If you cannot produce a valid JSON, return a JSON object (or an array of objects for batched input) following the schema shape and include a short explanation string describing the reason (still return valid JSON).\n\nInput:\n{\n  \"transaction_id\": \"T100099\",\n  \"baseline_score\": 0.005170091055333614,\n  \"features\": {\n    \"model_version\": \"xgb_v1\"\n  },\n  \"top_k_evidence\": [\n    {\n      \"id\": \"E1\",\n      \"text\": \"baseline=0.0000\"\n    },\n    {\n      \"id\": \"E2\",\n      \"text\": \"merchant_risk=?\"\n    },\n    {\n      \"id\": \"E3\",\n      \"text\": \"recent device mismatch\"\n    }\n  ],\n  \"max_delta\": 0.05\n}\n\nRespond with the JSON (a single JSON object for single-input or an array of objects for batched input) only.\n", "raw_output": "{\"transaction_id\":\"T100099\",\"llm_adjustment\":0,\"evidence_ids\":[\"E1\",\"E2\",\"E3\"]},{ \"transaction_id\":\"T100099\",\"llm_adjustment\":0.05,\"evidence_ids\":[\"E1\",\"E2\",\"E3\"]}\"\n\n", "model": "llama3.2:1b", "elapsed_seconds": 6.388447999954224}
